\input{preambuloSimple.tex}
\graphicspath{ {./images/} }
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{soul}


%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{	
\normalfont \normalsize 
\textsc{\textbf{Introducción a la Ciencia de Datos (2019)} \\ Máster Oficial Universitario en Ciencia de Datos e Ingeniería de Computadores \\ Universidad de Granada} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Trabajo Integrador: EDA, Clasificación y Regresión \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Luis Balderas Ruiz \\ \texttt{luisbalderas@correo.ugr.es}} 
 % Nombre y apellidos 


\date{\normalsize\today} % Incluye la fecha actual

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Muestra el Título

\newpage %inserta un salto de página

\tableofcontents % para generar el índice de contenidos

\listoffigures

\listoftables

\newpage

%
%\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
%	\centering
%	\includegraphics[scale=0.6]{e1.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
%	\caption{Progresión de la imagen de E en cada iteración} 
%	\label{fig:e1}
%\end{figure}


%----------------------------------------------------------------------------------------
%	Introducción
%----------------------------------------------------------------------------------------

\section{Introducción}


El presente documento contiene los resultados obtenidos en el Trabajo Teórico/Práctico Integrador para la evaluación de la asignatura Introducción a la Ciencia de Datos. El trabajo está formado por tres apartados, a saber, análisis de datos (en adelante EDA), regresión y clasificación, centrado en dos conjuntos de datos: Wankara para regresión y Vowel para clasificación. Ambos dos forman parte del repositorio de Keel (\cite{keel}), el primero en \cite{wankara} y el segundo en \cite{vowel}. A continuación, describo la estructura del documento. En la primera sección, se desarrolla el análisis exploratorio de ambos datasets. A continuación, tras sacar las conclusiones correspondientes, ataco el problema de regresión y, por último, el de clasificación.






%----------------------------------------------------------------------------------------
%	Análisis de datos
%----------------------------------------------------------------------------------------

\section{Análisis exploratorio de datos (EDA)}

\subsection{Conjunto de datos Wankara}

El presente conjunto de datos contiene información sobre el tiempo atmosférico entre los días 01/01/1994 y 28/05/1998 en la ciudad de Ankara, Turquía. En total, 1609 días (tantos como instancias) con información expresada en 10 variables numéricas que son las siguientes:

\begin{itemize}
	\item Max-temperature: Temperatura máxima del día (ºF).
	\item Min-temperature: Temperatura mínima del día (ºF).
	\item Dewpoint:  (Punto de rocío) Es la más alta temperatura a la que empieza a condensarse el vapor de agua contenido en el aire, produciendo rocío, neblina, cualquier tipo de nube o, en caso de que la temperatura sea lo suficientemente baja, escarcha (ºF).
	\item Precipitation: Cantidad de precipitaciones en el día(mm).
	\item Sea-level-pressure: Presión a nivel del mar (suponemos que en P).
	\item Standard-pressure: Presión estándar (suponemos que en P).
	\item Visibility: Medida de la mayor distancia en la cual un objeto puede verse de forma nítida (suponemos millas).
	\item Wind-speed: Velocidad del viento (suponemos mph).
	\item Max-wind-speed: Velocidad máxima del viento (suponemos mph).
	\item Mean-temperature (variable a modelar): temperatura media del día (ºF).
\end{itemize}

Tras entender el significado de cada variable y antes de empezar a estudiarlas un poco una a una, conviene tener una idea general de cuál es la tendencia entre las variables. Para ello, presento el siguiente gráfico:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{primer-vistazo-wankara.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Primer vistazo a las variables} 
	\label{fig:pvwankara}
\end{figure}

En cada plot enfrento la variable que queremos modelar, Mean-temperature, y las demás. Como se puede ver, hay tendencias muy claras entre Max-temperature, Min-temperature o Dewpoint y Mean-temperature. Las estudiaremos más a fondo a continuación para poder elegir correctamente los regresores. Hay que señalar que no existen valores perdidos en el conjunto de datos. Pasamos a estudiar cada variable de forma individual.


\subsubsection{Max-temperature}

La variable Max-temperature mide, en grados Fahrenheit, la temperatura máxima de cada día en Ankara. Presento primero un resumen estadístico de la misma:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín.  & 1st Qu. & Median & Mean  & SD      & 3rd Qu. & Max    \\ \hline
		23.00 & 46.40   & 60.80  & 77.40 & 17.8727 & 77.40   & 100.00 \\ \hline
	\end{tabular}
\end{table}


Además, los valores de asimetría es $0.0197847$ y curtosis, $-1.138017$, por lo que hay una muy ligera asimetría hacia la derecha y la distribución es platicúrtica. Veamos su histograma

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-max-temp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Max-temperature} 
	\label{fig:hist-max-temp}
\end{figure}

en el que vemos que los valores se concentran mayoritariamente en 40ºF y 80ºF aproximadamente. Este hecho se justifica con la estacionalidad, ya que los veranos de Ankara son calurosos y rondan los 30ºC (80ºF) (\cite{ankara-weather}). Respecto de outliers, la herramienta del paquete \textit{outliers} nos dice que encuentra el valor 23.0 como outlier por la izquierda y 100.0 por la derecha, mínimo y máximo de la muestra respectivamente, y se puede ver en el histograma que apenas están representados. En efecto, 100ºF es un valor muy alto para Ankara (difícilmente se pasa de los 35ºC (\cite{ankara-weather})) y 23ºF roza sobrepasa los mínimos habituales. \\

Por último, comprobamos con los test de normalidad Shapiro-Wilk (\cite{10.1093/biomet/52.3-4.591}) y la corrección de Lilliefors del test de Kolmogorov-Smirnov (\cite{10.1080/01621459.1967.10482916}, si la distribución de la variables es normal:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-max-temp.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-max-temp}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-max-temp.png}	\caption{Lilliefors}
		\label{fig:l-max-temp}
	\end{subfigure}
	\caption{Tests de normalidad sobre Max-temperature}
	\label{fig:norm-max-temp}
\end{figure}

cuyos p-valores son menores que 0.05 y, por tanto, rechazamos la hipótesis de normalidad. Mostramos el gráfico QQ:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-max-temp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Max-temperature} 
	\label{fig:qq-max-temp}
\end{figure}

donde claramente se ve que, efectivamente, la variable no se distribuye según una normal.

\subsubsection{Min-temperature}

La variable Min-temperature mide, en grados Fahrenheit, la temperatura mínima de cada día en Ankara. Presento primero un resumen estadístico de la misma:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean  & SD       & 3rd Qu. & Max  \\ \hline
		-7.1 & 26.60   & 36.00  & 37.08 & 13.34527 & 48.20   & 65.5 \\ \hline
	\end{tabular}
\end{table}

con valores de asimetría -0.055429 (ligeramente hacia la izquierda) y curtosis -0.7089539 (platicúrtica). Veamos su histograma.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-min-temp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Min-temperature} 
	\label{fig:hist-min-temp}
\end{figure}

con una media de 37.08ºF aunque también vemos un repunte cerca de los 50ºF, lo que nos muestra temperaturas suaves en gran parte de los días. Respecto de outliers, encontramos valores de -7.1 ºF (-22ºC), claramente irregulares en la tendencia general de la temperatura mínima, por lo que pudo darse una ola de frío sin precedentes o errores en la medición.\\
Si aplicamos los test de normalidad,

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-min-temp.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-min-temp}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-min-temp.png}	\caption{Lilliefors}
		\label{fig:l-min-temp}
	\end{subfigure}
	\caption{Tests de normalidad sobre Min-temperature}
	\label{fig:norm-min-temp}
\end{figure}

vemos que rechazamos la hipótesis de normalidad. En efecto, a través del QQPlot comprobamos que así es.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-min-temp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Min-temperature} 
	\label{fig:qq-min-temp}
\end{figure}


\subsubsection{Dewpoint}


La variable Dewpoint se almacena la más alta temperatura a la que empieza a condensarse el vapor de agua contenido en el aire, produciendo rocío, neblina, cualquier tipo de nube o, en caso de que la temperatura sea lo suficientemente baja, escarcha (ºF). Veamos un resumen estadístico:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean  & SD       & 3rd Qu. & Max   \\ \hline
		-3.1 & 28.50   & 36.80  & 36.29 & 10.81945 & 45.30   & 57.60 \\ \hline
	\end{tabular}
\end{table}

con valores de asimetría $-0.3740575$ (por la izquierda) y curtosis $-0.4824467$ (platicúrtica). Veamos su histograma.

 
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-dew.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Dewpoint} 
	\label{fig:hist-dew}
\end{figure}

donde confirmamos la asimetría por la derecha y vemos como la media y la mediana están bastante cercanas. Respecto de outliers, la herramienta nos informa de los valores $-3.1$ y $57.60$, como posibles candidatos, dada su escasez de apariciones. Podremos contrastarlo más detenidamente después. Si aplicamos los tests de normalidad 

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-dew.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-dew}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-dew.png}	\caption{Lilliefors}
		\label{fig:l-dew}
	\end{subfigure}
	\caption{Tests de normalidad sobre Dewpoint}
	\label{fig:norm-dew}
\end{figure}

vemos que rechazamos la hipótesis de normalidad. En efecto, a través del QQPlot comprobamos que así es.


\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-dew.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Dewpoint} 
	\label{fig:qq-dew}
\end{figure}


\subsubsection{Precipitation}

La variable Precipitation refleja la cantidad de precipitaciones (mm) en un día. Veamos un resumen estadístico de su contenido.

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean   & SD        & 3rd Qu. & Max \\ \hline
		0    & 0       & 0      & 0.0541 & 0.1844009 & 0       & 4   \\ \hline
	\end{tabular}
\end{table}

Podemos ver el escaso nivel de precipitaciones. Respecto de la asimetría (11.07923), es asimétrica por la derecha y presenta una curtosis de 194.1193 (leptocúrtica). Veamos su histograma:


 
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-pre.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Precipitation} 
	\label{fig:hist-pre}
\end{figure}

en el que confirmamos el nivel de sequía (casi 1250 días sin llover). Encontramos un par de días con un nivel de lluvia de 4mm y 3.2mm, lo que pueden ser errores en la medición días extraordinariamente lluviosos para el histórico de la ciudad. Aplicando los tests de normalidad

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-prec.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-pre}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-pre.png}	\caption{Lilliefors}
		\label{fig:l-pre}
	\end{subfigure}
	\caption{Tests de normalidad sobre Precipitation}
	\label{fig:norm-pre}
\end{figure}

vemos que por sus p-valores debemos rechazar la hipótesis de normalidad. 

\subsubsection{Sea-level-pressure}

En esta variable se aloja la presión a nivel del mar diaria en Ankara. A continuación, presento un resumen estadístico de la misma:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín.  & 1st Qu. & Median & Mean  & SD        & 3rd Qu. & Max   \\ \hline
		29.46 & 29.83   & 29.96  & 29.98 & 0.2015043 & 30.11   & 30.60 \\ \hline
	\end{tabular}
\end{table}

Cabe destacar del resumen estadístico la cercanía de la media y la mediana y la muy reducida variabilidad. Además, presenta una asimetría por la derecha (0.4085841) y es platicúrtica (-0.1849383 de curtosis), aunque cerca de ser mesocúrtica. Veamos el histograma:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-slp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Sea-level-pressure} 
	\label{fig:hist-slp}
\end{figure}

Vemos que su forma se asemeja a la de una distribución normal. Sin embargo aplicando los tests de normalidad,
\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-slp.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-slp}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-slp.png}	\caption{Lilliefors}
		\label{fig:l-slp}
	\end{subfigure}
	\caption{Tests de normalidad sobre Sea-level-pressure}
	\label{fig:norm-slp}
\end{figure}

vemos que se rechaza la hipótesis de normalidad en ambos tests. Podemos asegurarnos con el QQPlot de que, a pesar de que se parece a una normal, se sale de los rangos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-slp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Sea level pressure} 
	\label{fig:qq-slp}
\end{figure}


y por lo tanto, no sigue una distribución normal.

\subsubsection{Standard pressure}

Standard pressure representa la presión atmosférica diaria en la ciudad de Ankara. Veamos un resumen estadístico de la misma:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín.  & 1st Qu. & Median & Mean  & SD        & 3rd Qu. & Max   \\ \hline
		26.30 & 26.69   & 26.77  & 26.78 & 0.1383007 & 26.87   & 27.18 \\ \hline
	\end{tabular}
\end{table}

Vemos de nuevo una distribución de valores muy concentrada alrededor del 26.78, con media y medianas muy cercanas y apenas variabilidad. Por tanto, no se darán outliers. Además, no presenta asimetría (un escaso $-0.00832628$) y es leptocúrtica ($0.1495295$). Veamos su histograma. 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-sp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Standard pressure} 
	\label{fig:hist-sp}
\end{figure}

De nuevo vemos una distribución de valores que se parece a la normal. Comprobamos con los tests de normalidad

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-sp.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-sp}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-sp.png}	\caption{Lilliefors}
		\label{fig:l-sp}
	\end{subfigure}
	\caption{Tests de normalidad sobre Standard pressure}
	\label{fig:norm-sp}
\end{figure}

que debemos rechazar la hipótesis de normalidad. El gráfico QQ nos lo pone algo difícil en la confirmación:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-sp.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Standard Pressure} 
	\label{fig:qq-sp}
\end{figure}

ya que los puntos siempre lindan con los rangos permitidos. No obstante, prevalece para nosotros el diagnóstico de los tests de normalidad. 


\subsubsection{Visibility}

La variable Visibility contiene los datos acerca de la mayor distancia en la cual un objeto puede verse de forma nítida. Mostramos algunas estadísticas para conocerla mejor:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean  & SD      & 3rd Qu. & Max  \\ \hline
		0.2  & 7.4     & 8.3    & 7.718 & 1.47925 & 8.6     & 11.5 \\ \hline
	\end{tabular}
\end{table}


Encontramos gran distancia entre el valor mínimo y el primer cuartil, y teniendo en cuenta que la desviación estandar es 1.47925, podríamos estar ante un outlier. Además, la variable presenta asimetría hacia la izquierda (-1.947852) y es leptocúrtica (4.207581). Observamos el histograma de frecuencias

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-vis.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Visibility} 
	\label{fig:hist-vis}
\end{figure}

En él se observa bastante bien la asimetría y que los valores entorno a 8.3 son los más repetidos. Si estudiamos los tests de normalidad para Visibility

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-vis.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-vis}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-vis.png}	\caption{Lilliefors}
		\label{fig:l-vis}
	\end{subfigure}
	\caption{Tests de normalidad sobre Visibility}
	\label{fig:norm-vis}
\end{figure}

vemos que la variable no se distribuye como una normal. Lo confirmamos con el QQPlot:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-vis.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Visibility} 
	\label{fig:qq-vis}
\end{figure}

donde claramente la distribución está fuera de la tendencia de una normal.

\subsubsection{Wind speed}

Wind speed almacena los datos de la velocidad (entendemos que media) del viento en Ankara cada día. Estudiamos su resumen estadístico para comprenderla mejor:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean  & SD       & 3rd Qu. & Max \\ \hline
		0    & 3.11    & 5.06   & 5.393 & 3.041806 & 7.25    & 18  \\ \hline
	\end{tabular}
\end{table}

Como podemos ver, se trata de una distribución con media y mediana parecidas y con una considerable desviación típica. Además, los valores máximos y mínimos distan bastante de la media, especialmente el máximo, por lo que se puede tratar de un outlier tanto por un error de medida o por una ventisca. Por otra parte, la variable presenta una asimetría por la derecha (0.7321927) y es leptocúrtica (0.2130076). Veamos su histograma.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-ws.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Wind speed} 
	\label{fig:hist-ws}
\end{figure}

Vía el histograma, vemos que en Ankara siempre hace viento. Pocos días la velocidad del viento es 0. A falta de conocer la unidad de medida, podríamos decir que los vientos no son excesivamente virulentos.\\

Estudiamos si sigue una distribución normal vía los tests de normalidad.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-ws.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-ws}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-ws.png}	
		\caption{Lilliefors}
		\label{fig:l-ws}
	\end{subfigure}
	\caption{Tests de normalidad sobre Wind speed}
	\label{fig:norm-ws}
\end{figure}

Los p-valores nos dejan claro que debemos rechazar la hipótesis de normalidad. 

\subsubsection{Max wind speed}

En este caso, estudiamos la variable Max wind speed, con la velocidad máxima del viento cada día en Ankara. Veamos el estudio estadístico de la misma:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean  & SD       & 3rd Qu. & Max  \\ \hline
		2.19 & 10.2    & 12.7   & 13.32 & 5.498989 & 16.1    & 57.4 \\ \hline
	\end{tabular}
\end{table}

Evidentemente, los valores de esta variable son, para cada día, mayores o iguales que los de Wind speed. Aquí encontramos el valor que generaba el outlier (o ventisca) en Wind speed, que es 57.4, prácticamente 5 veces mayor que la media. Presenta, al igual que Wind speed, asimetría por la derecha (1.855093) más pronunciada y es leptocúrtica, con curtosis aún mayor (8.624427). Veamos el histograma.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-mws.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Max Wind speed} 
	\label{fig:hist-mws}
\end{figure}

En él podemos encontrar ciertos outliers cuando se supera el valor 30 de velocidad. Parece lógico pensar que no sigue una distribución normal dada la forma del histograma. Estudiamos los tests de normalidad para comprobarlo:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-mws.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-mws}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-mws.png}	
		\caption{Lilliefors}
		\label{fig:l-mws}
	\end{subfigure}
	\caption{Tests de normalidad sobre Max Wind speed}
	\label{fig:norm-mws}
\end{figure}

y su QQPlot

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{qq-mws.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de Max wind speed} 
	\label{fig:qq-mws}
\end{figure}

En efecto, rechazamos la hipótesis de normalidad.

\subsubsection{Mean temperatura}

Mean temperature contiene la temperatura media del día en Ankara. Es la variable que queremos aproximar a través de regresores y distintos modelos. A continuación mostraré una serie de hipótesis sobre ella y la relación con las demás variables. Así podremos descubrir cómo aproximarla de forma efectiva y eficiente. Antes de eso, estudiamos su resumen estadístico:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		Mín. & 1st Qu. & Median & Mean  & SD      & 3rd Qu. & Max \\ \hline
		7.90 & 36.7    & 48.5   & 49.56 & 15.4564 & 63.3    & 81  \\ \hline
	\end{tabular}
\end{table}

Podemos ver que, con excepción de días muy fríos o algo calurosos, la temperatura media en Ankara se mantiene fría (48.5ºF, menos de 10ºC). Desde el punto de vista más estadístico, apenas tiene asimetría a la derecha (0.03417221) y es platicúrtica (-1.060112). Veamos el histograma.


\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{hist-mt.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de Mean temperature} 
	\label{fig:hist-mt}
\end{figure}


Parece como si fuera bimodal. En mi opinión, se corresponde con la estación fría y cálida, donde más se repiten las temperaturas. Veamos si sigue una distribución normal:


\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{shapiro-mt.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-mt}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{lillie-mt.png}	
		\caption{Lilliefors}
		\label{fig:l-mt}
	\end{subfigure}
	\caption{Tests de normalidad sobre Mean temperature}
	\label{fig:norm-mt}
\end{figure}

Por los p-valores, rechazamos la hipótesis de normalidad para la variable. 

\subsubsection{Algunas hipótesis previas a estudiar la correlación}

Parece lógico pensar que si las temperatura máxima de un día sube/baja, la temperatura media del mismo día tendrá el mismo comportamiento. De igual manera para la temperatura mínima y la media. Veamos si nuestros datos reflejan eso también.

\begin{itemize}
	\item \textbf{Hipótesis 1: cuanto mayor (menor) es la temperatura máxima, mayor (menor) es la temperatura media}
	
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.5]{hip1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Temperatura máxima vs media} 
		\label{fig:hip1}
	\end{figure}

En efecto, así es. Hay una dependencia lineal muy clara entre las variables.

	 \item \textbf{Hipótesis 2: cuanto mayor (menor) es la temperatura mínima, mayor (menor) es la temperatura media}
	 
	 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	 	\centering
	 	\includegraphics[scale=0.5]{hip2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	 	\caption{Temperatura mínima vs media} 
	 	\label{fig:hip2}
	 \end{figure}
 
Aunque la tendencia no es tan clara como en la gráfica anterior, también vemos cierta dependencia lineal entre las variables, cumpliéndose nuestra hipótesis.
	
\end{itemize}


\subsubsection{División por meses}

Durante el análisis exploratorio de datos, he tratado de separar los días por meses. Como se ha comentado, cada instancia corresponde con un día de entre el 01/01/1994 y el 28/05/1998. Habiéndolo llevado a cabo, incluso teniendo en cuenta que 1996 fue bisiesto, he intentado estudiar cómo varía la temperatura máxima y mínima (en media) por meses. Sin embargo, los resultados han sido insatisfactorios:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{div1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Temperatura máxima media de cada mes} 
	\label{fig:div1}
\end{figure}

Como se puede ver, la mayor temperatura máxima media de 1994 se dio en diciembre (invierno en Ankara) y la tercera más baja en julio (verano). Por tanto sospecho que las tuplas no están ordenadas por fecha. Continué estudiándolo para la temperatura mínima media por mes.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{div2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Temperatura mínima media de cada mes} 
	\label{fig:div2}
\end{figure}

De nuevo, los datos no tienen sentido porque la menor temperatura mínima se da en julio, con 18.7ºF (-7ºC). Por tanto, definitivamente, las instancias no están ordenadas por fechas y no puedo llevar a cabo un estudio mensual para encontrar patrones.

\newpage 
\subsubsection{Correlación de las variables}

Presentamos un gráfico resumen con la correlación de todas las parejas de variables y su nivel de significancia, tanto a través de scatter plots, histogramas y p-valores.


\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.9]{correlaciones.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resumen de la correlación} 
	\label{fig:correlaciones}
\end{figure}

Podemos ver que las variables más correladas con Mean temperature son Max temperature (0.97), Min temperature (0.94) y Dewpoint (0.90). Por el contrario, Precipition no tienen ninguna correlación con nuestro target. Además, descubrimos correlaciones entre los posibles regresores, que nos pueden dar motivo luego para eliminar uno u otro en los modelos predictivos. Es el caso de Min temperature y Dewpoint (0.92) O Sea level pressure y Standard pressure (0.90). Advertimos también ciertas correlaciones negativas, por ejemplo entre Sea level pressure y Mean temperature (-0.64). 

\subsubsection{Conclusiones}

El análisis exploratorio de datos realizado sobre el conjunto de datos Wankara nos arroja un montón de información sobre el tiempo en Ankara. Esta ciudad, situada en el centro de la península de Anatolia, presenta un clima más bien continental, con temperaturas frescas que en verano no superan los 38ºC (100ºF), con una temperatura media de 10ºC y con temperaturas mínimas que rondan los 0ºC, con extremos de hasta -22ºc (-7ºF). Además, presenta precipitaciones escasas. La influencia del mar en la ciudad es escasa por la distancia y las montañas que los separa. Podríamos estimar los niveles de contaminación atmosférica entre 1994 y 1998 si supiéramos la unidad de medida de la variable visibilidad. Por ejemplo, si se tratara de km, como la media está alrededor de 7, podríamos asumir que la contaminación es reducida. Tampoco parece ser una ciudad muy ventosa ni con rachas de viento muy fuertes, aunque realmente no conocemos la unidad de medida y los números pueden ser engañosos. Además, hemos constatado que el dataset no está ordenado por fecha, por lo que no podemos encontrar patrones por meses.      


\newpage
\subsection{Conjunto de datos Vowel}

El presente conjunto de datos contiene información sobre el reconocimiento de las once vocales existentes en inglés por parte de 15 interlocutores independientes. Es un problema de clasificación de once clases (las once vocales inglesas) con trece características, diez de ellas reales y tres enteras. A pesar de ser numéricas, esas tres variables son realmente categóricas, dado que

\begin{itemize}
	\item TT (0/1): Indica si la instancia es de entrenamiento (0) o test (1).
	\item Sex (0/1): Indica el género del hablante en dicha instancia.
	\item SpeakerNumber [0,14]: Indica el interlocutor de la instancia.
\end{itemize}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.7]{dist-sexos.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Distribución por sexos de los interlocutores} 
	\label{fig:dist-sex}
\end{figure}

Por tanto, esas variables se pueden interpretar como factores más que numéricas. De hecho, TT será ignorada en el EDA porque es conveniente realizar el estudio sobre los datos al completo. Por tanto, tras estas modificaciones contamos con diez variables reales (F0-F9), dos factores (sexo y número de interlocutor) y once clases (0-10), con un total de 990 instancias. 

Para explorar los datos, en primer lugar, calculo un resumen estadístico de cada variable y su dispersión. En las variables categóricas encontramos:

\begin{itemize}
	\item Cada interlocutor tiene 66 apariciones en el conjunto de datos.
	\item 528 de ellos son hombres y 462 mujeres.
\end{itemize}

Para las variables numéricas, los resultados son los siguientes:

\begin{table}[H]
	\resizebox{\textwidth}{!}{\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		& \textbf{F0} & \textbf{F1} & \textbf{F2} & \textbf{F3} & \textbf{F4} & \textbf{F5} & \textbf{F6} & \textbf{F7} & \textbf{F8} & \textbf{F9} \\ \hline
		\textbf{Min}     & -5.211      & -1.274      & -2.487      & -1.409      & -2.127      & -0.836      & -1.537      & -1.293      & -1.631      & -1.68       \\ \hline
		\textbf{1st Qua} & -3.888      & 1.052       & -0.97575    & -0.0655     & -0.769      & 0.196       & -0.307      & -0.09575    & -0.704      & -0.548      \\ \hline
		\textbf{Mediana} & -3.146      & 1877        & -0.5725     & 0.4335      & -0.299      & 0.552       & 0.022       & 0.328       & -0.3025     & -0.1565     \\ \hline
		\textbf{Media}   & -3.204      & 1.882       & -0.50777    & 0.5155      & -0.3057     & 0.6302      & -0.004365   & 0.33655     & -0.30298    & -0.07134    \\ \hline
		\textbf{3th Qua} & -2.603      & 2.738       & -0.06875    & 1.096       & 0.1695      & 1.0285      & 0.2965      & 0.77        & 0.09375     & 0.371       \\ \hline
		\textbf{Max}     & -0.941      & 5.074       & 1.431       & 2.377       & 1.831       & 2.327       & 1.403       & 2.039       & 1.309       & 1.396       \\ \hline
		\textbf{SD}      & 0.8689872   & 1.1752720   & 0.7119483   & 0.7592613   & 0.6646023   & 0.6038711   & 0.4619268   & 0.5733020   & 0.5701616   & 0.6039855   \\ \hline
	\end{tabular}}
	\caption{Resumen estadístico y desviación típica de las características reales}
\end{table}

Como se puede observar, el rango y el dominio de cada variable es distinto, lo que podría condicionar el rendimiento de los posteriores algoritmos que utilizaremos. Por tanto, será necesario un reescalado de las mismas para evitar esa discriminación positiva de unas variables respecto a otras sólo por ser "mayores". \\

A continuación, presento las 10 variables numéricas con más detenimiento. Una de las características principales de este conjunto de datos es que, si se estudia como un todo, el comportamiento de las variables a veces puede parecer errático. Sin embargo, no se debe soslayar el hecho de que tenemos una variable categórica, la del sexo, que nos hace prácticamente crear dos conjuntos de datos cuasi-independientes: hombres y mujeres, donde sí que encontramos correlaciones y claves para entender el funcionamiento de las características. Como digo, presento cada una de las variables, primero estudiándola en conjunto y luego separando por sexo. Para comprobar si las variables siguen una distribución normal, se han utilizado el test de Shapiro-Wilk (\cite{10.1093/biomet/52.3-4.591}) y la corrección de Lilliefors del test de Kolmogorov-Smirnov (\cite{10.1080/01621459.1967.10482916}). Además, para estudiar el comportamiento tanto por sexo como por interlocutor, represento vía boxplots cada variable.
\newpage

\subsubsection{F0}

Presentamos la variable F0. En primer lugar, reflejo un resumen estadístico de la misma así como su histograma diferenciando entre hombres y mujeres.
\begin{itemize}
	\item Media: -3.204
	\item Mediana: -3.146
	\item Desviación típica: 0.8689872
	\item Rango: [-5.211,-0.941]
	\item Primer y tercer cuartiles: (-3.888,-2.603)
	\item Asimetría: 0.0662973
	\item Curtosis: -0.4974651
\end{itemize}

Por el valor de la curtosis, la variable es platicúrtica y muy ligeramente asimétrica por la derecha.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F0.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F0} 
	\label{fig:hist-F0}
\end{figure}

Pasamos a comprobar si F0 se distribuye según una normal. Para ello, establecemos los tests de hipótesis de Shapiro-Wilk y Lilliefors (Kolmogorov-Smirnov) con los siguientes resultados:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F0.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F0}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{l-F0.png}
		\caption{Lilliefors}
		\label{fig:l-F0}
	\end{subfigure}
	\caption{Tests de normalidad sobre F0}
	\label{fig:normF0}
\end{figure}

Como los p-valores son menores que 0.05, rechazamos la hipótesis nula (la variable sigue una distribución normal). \\


A continuación presento los boxplots:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps0.png}
		\caption{Por sexo}
		\label{fig:bps0}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn0.png}
		\caption{Por interlocutor}
		\label{fig:bpsn0}
	\end{subfigure}
	\caption{Boxplot para F0 estudiando sexos e interlocutores}
	\label{fig:bf0}
\end{figure}

Como se puede ver, existe un outlier en el interlocutor 7. Además, observamos que los valores para los hombres tienden a ser mayores que para las mujeres. \\

Si ahora estudiamos los tests de normalidad por sexos, encontramos los siguientes resultados:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F0.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F0}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F0.png}
		\caption{Lilliefors}
		\label{fig:lh-F0}
	\end{subfigure}
	\caption{Tests de normalidad sobre F0 (hombres)}
	\label{fig:normhF0}
\end{figure}

En este caso, aunque también se rechaza la hipótesis de normalidad, el test de Lilliefors arroja un resultado menor pero cercano a 0.05, por lo que parece acercarse más la variable en los hombres a una distribución normal que con el conjunto completo. \\

Para las mujeres,

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F0.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F0}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F0.png}
		\caption{Lilliefors}
		\label{fig:lm-F0}
	\end{subfigure}
	\caption{Tests de normalidad sobre F0 (mujeres)}
	\label{fig:normmF0}
\end{figure}

se encuentran unos p-valores menores que para los hombres, por lo que también se rechaza la hipótesis de normalidad.

\subsubsection{F1}

Como en el apartado anterior, primero reflejo un resumen estadístico de la variable:

\begin{itemize}
	\item Media: 1.882
	\item Mediana: 1.877
	\item Desviación típica: 1.175272
	\item Rango: [-1.274,5.074]
	\item Primer y tercer cuartil: (1.052,2.738)
	\item Asimetría: -0.04269788
	\item Curtosis: -0.39925
\end{itemize}

Por el valor de la curtosis, la variable es platicúrtica y muy ligeramente asimétrica por la izquierda.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F1} 
	\label{fig:hist-F1}
\end{figure}

Pasamos a estudiar la normalidad de la variable. Estos son los resultados de los tests:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F1.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.75\linewidth]{l-F1.png}
		\caption{Lilliefors}
		\label{fig:l-F1}
	\end{subfigure}
	\caption{Tests de normalidad sobre F1}
	\label{fig:normF1}
\end{figure}

Encontramos una discrepancia en los tests. Según el p-valor de Shapiro-Wilk, debemos rechazar la hipótesis de normalidad. Sin embargo, Lilliefors nos indica (0.2628) que no podemos rechazarla. Para esclarecer un poco más el comportamiento de F1, realizo la gráfica de densidad con una normal superpuesta con la media y desviación típica de F1:

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
 	\centering
 	\includegraphics[scale=0.6]{density-F1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
 	\caption{Histograma con la densidad de F1 y normal para comparar} 
 	\label{fig:dense-F1}
 \end{figure}

así como un QQPlot (\cite{10.1093/biomet/55.1.1}):

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F1} 
	\label{fig:qq-F1}
\end{figure}

A la luz de los resultados, podemos interpretar que F1 tiene un comportamiento muy parecido a la distribución normal. A continuación, presento los boxplots:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps1.png}
		\caption{Por sexo}
		\label{fig:bps1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn1.png}
		\caption{Por interlocutor}
		\label{fig:bpsn1}
	\end{subfigure}
	\caption{Boxplot para F1 estudiando sexos e interlocutores}
	\label{fig:bf1}
\end{figure}

Podemos apreciar outliers en los interlocutores 3,8,13 y 14. \\

Si ahora estudiamos los tests de normalidad por sexos, encontramos los siguientes resultados. Para los hombres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F1.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F1.png}
		\caption{Lilliefors}
		\label{fig:lh-F1}
	\end{subfigure}
	\caption{Tests de normalidad sobre F1 (hombres)}
	\label{fig:normhF1}
\end{figure}

Ambos tests nos llevan a rechazar la hipótesis de normalidad. En el caso de las mujeres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F1.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F1.png}
		\caption{Lilliefors}
		\label{fig:lm-F1}
	\end{subfigure}
	\caption{Tests de normalidad sobre F1 (mujeres)}
	\label{fig:normmF1}
\end{figure}

también rechazamos la hipótesis nula. Por tanto, en conjunto la variable se comporta según una normal pero por separado (hombres/mujeres) no.

\subsubsection{F2}

Presentamos la variable F2. En primer lugar, reflejo un resumen estadístico de la misma así como su histograma diferenciando entre hombres y mujeres.
\begin{itemize}
	\item Media: -0.50777
	\item Mediana: -0.5725
	\item Desviación típica: 0.7119483
	\item Rango: [-2.487,-1.431]
	\item Primer y tercer cuartiles: (-0.97575,-0.06875)
	\item Asimetría: 0.2352169
	\item Curtosis: -0.1575597
\end{itemize}

Por el valor de la curtosis, la variable es platicúrtica y ligeramente asimétrica por la derecha.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F2} 
	\label{fig:hist-F2}
\end{figure}


Pasamos a estudiar la normalidad de la variable. Estos son los resultados de los tests:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F2.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F2}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{l-F2.png}
		\caption{Lilliefors}
		\label{fig:l-F2}
	\end{subfigure}
	\caption{Tests de normalidad sobre F2}
	\label{fig:normF2}
\end{figure}

Ambos tests nos indican que debemos rechazar la hipótesis de normalidad. En cuanto a los boxplots:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps2.png}
		\caption{Por sexo}
		\label{fig:bps2}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn2.png}
		\caption{Por interlocutor}
		\label{fig:bpsn2}
	\end{subfigure}
	\caption{Boxplot para F2 estudiando sexos e interlocutores}
	\label{fig:bf2}
\end{figure}

Encontramos en F2 una gran concentración de outliers para los interlocutores 5,6,10,11 y 13. Es posible que las mediciones hayan sido erróneas. En cualquier caso, podría ser importante la aplicación de técnicas para la disminución de estos valores extraños. \\

Si ahora estudiamos los tests de normalidad por sexos, encontramos los siguientes resultados:
\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F2.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F2}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F2.png}
		\caption{Lilliefors}
		\label{fig:lh-F2}
	\end{subfigure}
	\caption{Tests de normalidad sobre F2 (hombres)}
	\label{fig:normhF2}
\end{figure}






\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F2.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F2}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F2.png}
		\caption{Lilliefors}
		\label{fig:lm-F2}
	\end{subfigure}
	\caption{Tests de normalidad sobre F2 (mujeres)}
	\label{fig:normmF2}
\end{figure}

Para ambos subconjuntos, los tests nos indican que debemos rechazar la hipótesis de normalidad.

\subsubsection{F3}

Como en el apartado anterior, primero reflejo un resumen estadístico de la variable:

\begin{itemize}
	\item Media: 0.5155
	\item Mediana: 0.4335
	\item Desviación típica: 0.7592613
	\item Rango: [-1.409,2.377]
	\item Primer y tercer cuartil: (-0.0655,1.096)
	\item Asimetría: 0.1287436
	\item Curtosis: -0.39925
\end{itemize}

Por el valor de la curtosis, la variable es platicúrtica y ligeramente asimétrica por la derecha.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F3} 
	\label{fig:hist-F3}
\end{figure}

Evalúo ahora los tests de normalidad:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F3.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{l-F3.png}
		\caption{Lilliefors}
		\label{fig:l-F3}
	\end{subfigure}
	\caption{Tests de normalidad sobre F3}
	\label{fig:normF3}
\end{figure}

Como se puede ver, rechazamos la hipótesis de normalidad por ser los p-valores menores de 0.05. \\

Estudiamos ahora los boxplots:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps3.png}
		\caption{Por sexo}
		\label{fig:bps3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn3.png}
		\caption{Por interlocutor}
		\label{fig:bpsn3}
	\end{subfigure}
	\caption{Boxplot para F3 estudiando sexos e interlocutores}
	\label{fig:bf3}
\end{figure}

Como se puede observar, los interlocutores 1,3 y 9 tienen bastantes outliers, mientras que los 2, 8 y 10 presentan outliers en menor medida. Con respecto a los tests de normalidad para hombres y mujeres, vemos que debemos rechazar la hipótesis de normalidad en ambos casos:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F3.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F3.png}
		\caption{Lilliefors}
		\label{fig:lh-F3}
	\end{subfigure}
	\caption{Tests de normalidad sobre F3 (hombres)}
	\label{fig:normhF3}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F3.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F3.png}
		\caption{Lilliefors}
		\label{fig:lm-F3}
	\end{subfigure}
	\caption{Tests de normalidad sobre F3 (mujeres)}
	\label{fig:normmF3}
\end{figure}

\subsubsection{F4}

En primer lugar, reflejo un resumen estadístico de la variable:

\begin{itemize}
	\item Media: -0.3057
	\item Mediana: -0.299
	\item Desviación típica: 0.6646023
	\item Rango: [-2.127,1.831]
	\item Primer y tercer cuartil: (-0.769,0.1695)
	\item Asimetría: 0.01647417
	\item Curtosis: -0.2773318
\end{itemize}

Por el valor de la curtosis, la variable es platicúrtica y apenas asimétrica por la derecha. Presentamos el histograma para conocer más los datos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F4.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F4} 
	\label{fig:hist-F4}
\end{figure}

Pasamos a comprobar si F4 se distribuye según una normal. Para ello, establecemos los tests de hipótesis de Shapiro-Wilk y Lilliefors:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F4.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F4}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{l-F4.png}
		\caption{Lilliefors}
		\label{fig:l-F4}
	\end{subfigure}
	\caption{Tests de normalidad sobre F4}
	\label{fig:normF4}
\end{figure}

Ambos tests indican que no podemos rechazar la hipótesis de normalidad. Confirmamos el resultado con el gráfico QQPlot.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F4.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfico QQPlot de F4} 
	\label{fig:qq-F4}
\end{figure} 

Por tanto, podemos asumir que F4 se distribuye como una normal. Estudiamos ahora los boxplots:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps4.png}
		\caption{Por sexo}
		\label{fig:bps4}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn4.png}
		\caption{Por interlocutor}
		\label{fig:bpsn4}
	\end{subfigure}
	\caption{Boxplot para F4 estudiando sexos e interlocutores}
	\label{fig:bf4}
\end{figure}

donde apreciamos una cantidad considerable de outliers en el interlocutor 12. Además, en esta variable, las mujeres consiguen valores más altos que los hombres. \\

Por último, estudiamos los tests de normalidad por sexo. En el caso de los hombres, 

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F4.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F4}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F4.png}
		\caption{Lilliefors}
		\label{fig:lh-F4}
	\end{subfigure}
	\caption{Tests de normalidad sobre F4 (hombres)}
	\label{fig:normhF4}
\end{figure}

el test de Shapiro-Wilk indica que no podemos rechazar la hipótesis de normalidad (p valor 0.07) mientras que el de Lilliefors indica que la rechacemos. En la literatura, el test de Lilliefors resulta más fiable que el de Shapiro-Wilk por el número de instancias que tenemos, así que rechazamos la hipótesis de normalidad. \\

Para las mujeres,

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F4.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F4}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F4.png}
		\caption{Lilliefors}
		\label{fig:lm-F4}
	\end{subfigure}
	\caption{Tests de normalidad sobre F4 (mujeres)}
	\label{fig:normmF4}
\end{figure}

los p-valores son bastante mayores que 0.05, por lo que no podemos rechazar la hipótesis de normalidad. Para confirmarlo, mostramos el QQPlot de F4 para mujeres.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F4m.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Gráfico QQPlot de F4 (mujeres)} 
	\label{fig:qq-F4m}
\end{figure} 

Efectivamente, las instancias de F4 de sexo femenino siguen una distribución normal.

\subsubsection{F5}

A continuación presentamos la variable F5. Como en los casos anteriores, comenzamos por un resumen estadístico:
\begin{itemize}
	\item Media: 0.6302
	\item Mediana: 0.552
	\item Desviación típica: 0.6038711 
	\item Rango: [-0.836,2.327]
	\item Primer y tercer cuartil: (0.196,1.0285)
	\item Asimetría: 0.3559791
	\item Curtosis: -0.2964589
\end{itemize}

A la vista de los resultados, la variable es platicúrtica y ligeramente asimétrica hacia la derecha. Veamos ahora el histograma separado por sexos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F5.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F5} 
	\label{fig:hist-F5}
\end{figure}

Estudio si F5 se distribuye según una normal vía los tests estadísticos. Los resultados son los siguientes:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F5.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F5}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{l-F5.png}
		\caption{Lilliefors}
		\label{fig:l-F5}
	\end{subfigure}
	\caption{Tests de normalidad sobre F5}
	\label{fig:normF5}
\end{figure}

Ambos tests nos indican que debemos rechazar la hipótesis de normalidad por el bajo p-valor. Si estudiamos los boxplots, encontramos que

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps5.png}
		\caption{Por sexo}
		\label{fig:bps5}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn5.png}
		\caption{Por interlocutor}
		\label{fig:bpsn5}
	\end{subfigure}
	\caption{Boxplot para F5 estudiando sexos e interlocutores}
	\label{fig:bf5}
\end{figure}

con apenas outliers en los interlocutores 11 y 14. Paso a estudiar la distribución por sexos. En el caso de los hombres, comprobamos la normalidad

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F5.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F5}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F5.png}
		\caption{Lilliefors}
		\label{fig:lh-F5}
	\end{subfigure}
	\caption{Tests de normalidad sobre F5 (hombres)}
	\label{fig:normhF5}
\end{figure}

rechazando la hipótesis de normalidad como consecuencia de los dos tests. Para las mujeres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F5.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F5}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F5.png}
		\caption{Lilliefors}
		\label{fig:lm-F5}
	\end{subfigure}
	\caption{Tests de normalidad sobre F5 (mujeres)}
	\label{fig:normmF5}
\end{figure}

encontramos que Shapiro-Wilk nos indica que rechacemos la hipótesis de normalidad (0.04365 < 0.05) pero Lilliefors no (0.08174>0.05). Como siempre, le doy mayor credibilidad al test de Lilliefors, por lo que no podemos rechazar la hipótesis de normalidad. Para confirmarlo, muestro el gráfico QQ.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F5m.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F5 (mujeres)} 
	\label{fig:qq-F5m}
\end{figure}

En efecto, la gráfica nos muestra que la variable se distribuye al menos de forma muy pareja a la normal. Volvemos a encontrar un caso donde el subconjunto de interlocutores masculinos difiere en distribución respecto del femenino.

\subsubsection{F6}

El resumen estadístico de la variable F6 es el siguiente:

\begin{itemize}
	\item Media: -0.004365
	\item Mediana: 0.022
	\item Desviación típica: 0.4619268
	\item Rango: [-1.537,1.403]
	\item Primer y tercer cuartiles: (-0.307,0.2965)
	\item Asimetría: -0.2055278
	\item Curtosis: 0.139262
\end{itemize}

Por lo que la variable F6 tiene una asimetría por la izquierda y es leptocúrtica. Veamos su histograma para confirmarlo.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F6.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F6} 
	\label{fig:hist-F6}
\end{figure}

Examinamos si se distribuye como una normal con los tests siguientes.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F6.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F6}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{l-F6.png}
		\caption{Lilliefors}
		\label{fig:l-F6}
	\end{subfigure}
	\caption{Tests de normalidad sobre F6}
	\label{fig:normF6}
\end{figure}

De nuevo, Shapiro-Wilk nos indica que rechacemos la hipótesis de normalidad mientras Kolmogorov-Smirnov no nos da motivos suficientes para rechazar la hipótesis. Confirmamos que se distribuye como una normal gracias al gráfico QQ.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F6.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F6} 
	\label{fig:qq-F6}
\end{figure}

quedándose dentro de los márgenes de la normal, por lo que asumimos que F6 se distribuye como una normal. Examinemos más detenidamente su comportamiento con boxplots:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps6.png}
		\caption{Por sexo}
		\label{fig:bps6}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn6.png}
		\caption{Por interlocutor}
		\label{fig:bpsn6}
	\end{subfigure}
	\caption{Boxplot para F6 estudiando sexos e interlocutores}
	\label{fig:bf6}
\end{figure}

Encontramos en ellos una gran cantidad de outliers, sobre todo concentrados en el sexo masculino (interlocutor 3 especialmente). Veamos ahora la distribución por sexos vía los tests estadísticos.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F6.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F6}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F6.png}
		\caption{Lilliefors}
		\label{fig:lh-F6}
	\end{subfigure}
	\caption{Tests de normalidad sobre F6 (hombres)}
	\label{fig:normhF6}
\end{figure}

El test de Shapiro-Wilk nos indica que rechacemos la hipótesis de normalidad mientras que Lilliefors, con un p-valor de 0.05132, no puede rechazar la hipótesis nula, aunque con muy poca certeza estadística. El gráfico QQ nos confirma que las colas de los datos están fuera del comportamiento de la distribución normal, por lo que el p-valor se acerca mucho a 0.05.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F6h.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F6 (hombres)} 
	\label{fig:qq-F6h}
\end{figure}

Este resultado puede venir influenciado por la gran cantidad de outliers. En el caso de las mujeres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F6.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F6}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F6.png}
		\caption{Lilliefors}
		\label{fig:lm-F6}
	\end{subfigure}
	\caption{Tests de normalidad sobre F6 (mujeres)}
	\label{fig:normmF6}
\end{figure}

ambos tests nos indican que no podemos rechazar la hipótesis de normalidad. Además, el gráfico QQ nos lo confirma

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F6m.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F6 (mujeres)} 
	\label{fig:qq-F6m}
\end{figure}

por lo que asumimos que la variable F6 para las mujeres sigue una distribución normal.

\subsubsection{F7}

Como en todas las anteriores, presento el resumen estadístico de la variable F7 y su histograma.

\begin{itemize}
	\item Media: 0.33655
	\item Mediana: 0.328
	\item Desviación típica: 0.5733020
	\item Rango: [-1.293,2.039]
	\item Primer y tercer cuartiles: (-0.09575,0.77)
	\item Asimetría: 0.005939385
	\item Curtosis: -0.4980897
\end{itemize}


La variable apenas presenta asimetría por la derecha y es platicúrtica.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F7.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F7} 
	\label{fig:hist-F7}
\end{figure}

Podemos ver, gracias al histograma, que la población de mujeres tiene gran asimetría por la derecha (0.4939301). Estudiando los tests estadísticos para la normalidad

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F7.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F7}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{l-F7.png}
		\caption{Lilliefors}
		\label{fig:l-F7}
	\end{subfigure}
	\caption{Tests de normalidad sobre F7}
	\label{fig:normF7}
\end{figure}

vemos que ambos tests nos hacen rechazar la hipótesis de normalidad. Si observamos los boxplots

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps7.png}
		\caption{Por sexo}
		\label{fig:bps7}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn7.png}
		\caption{Por interlocutor}
		\label{fig:bpsn7}
	\end{subfigure}
	\caption{Boxplot para F7 estudiando sexos e interlocutores}
	\label{fig:bf7}
\end{figure}

vemos varios outliers de nuevo sobre todo en los hombres (interlocutores 2,3 y 11). Si estudiamos estos conjuntos por separado

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F7.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F7}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F7.png}
		\caption{Lilliefors}
		\label{fig:lh-F7}
	\end{subfigure}
	\caption{Tests de normalidad sobre F7 (hombres)}
	\label{fig:normhF7}
\end{figure}

ambos estadísticos nos hacen rechazar la hipótesis de normalidad (con posibles modificaciones tras tratar los outliers), al igual que las mujeres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F7.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F7}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F7.png}
		\caption{Lilliefors}
		\label{fig:lm-F7}
	\end{subfigure}
	\caption{Tests de normalidad sobre F7 (mujeres)}
	\label{fig:normmF7}
\end{figure}

Debido a la asimetría, una transformación de tipo logaritmo o raíz cuadrada podría corregirse y dar lugar, además, a una distribución más parecida a la normal.

\subsubsection{F8}

He aquí el resumen estadístico e histograma de la variable F8:

\begin{itemize}
	\item Media: -0.30298
	\item Mediana: -0.3025
	\item Desviación típica: 0.5701616
	\item Rango: [-1.631,1.309]
	\item Primer y tercer cuartiles: (-0.704,0.09375)
	\item Asimetría: 0.05370663
	\item Curtosis: -0.465887
\end{itemize}


La variable presenta asimetría por la derecha y es platicúrtica.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F8.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F8} 
	\label{fig:hist-F8}
\end{figure}

Estudio la distribución de F8 vía los tests estadísticos con hipótesis nula que la variable sigue una distribución normal.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F8.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F8}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{l-F8.png}
		\caption{Lilliefors}
		\label{fig:l-F8}
	\end{subfigure}
	\caption{Tests de normalidad sobre F8}
	\label{fig:normF8}
\end{figure}

El test de Lilliefors nos indica que no podemos rechazar la hipótesis de normalidad. Confirmamos este resultado con el gráfico QQ:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F8.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F8} 
	\label{fig:qq-F8}
\end{figure}

Si estudiamos los boxplots, vemos que la mayoría de los hombres tienen valores mayores que las mujeres. Además, encontramos ciertos outliers en los interlocutores 1,7 y 12.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps8.png}
		\caption{Por sexo}
		\label{fig:bps8}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn8.png}
		\caption{Por interlocutor}
		\label{fig:bpsn8}
	\end{subfigure}
	\caption{Boxplot para F8 estudiando sexos e interlocutores}
	\label{fig:bf8}
\end{figure}

Si estudiamos ambos sexos por separado, en primer lugar los hombres,

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F8.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F8}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F8.png}
		\caption{Lilliefors}
		\label{fig:lh-F8}
	\end{subfigure}
	\caption{Tests de normalidad sobre F8 (hombres)}
	\label{fig:normhF8}
\end{figure}

vemos que debemos rechazar la hipótesis de normalidad. Para las mujeres,

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F8.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F8}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F8.png}
		\caption{Lilliefors}
		\label{fig:lm-F8}
	\end{subfigure}
	\caption{Tests de normalidad sobre F8 (mujeres)}
	\label{fig:normmF8}
\end{figure}

el test de Shapiro-Wilk nos invita a rechazar la hipótesis de normalidad, mientras que el de Lilliefors no encuentra suficientes motivos para rechazar la hipótesis de normalidad (p-valor > 0.05). Confirmamos ese resultado con el gráfico QQ:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{qq-F8m.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{QQPlot de la variable F8 (mujers)} 
	\label{fig:qq-F8m}
\end{figure}

donde vemos que la variable siempre se queda entre los márgenes establecidos para un comportamiento "normal". Vemos de nuevo una discrepancia entre el subconjunto de interlocutores masculinos y femeninos.

\subsubsection{F9}

Presentamos el resumen estadístico de la última variable, F9, junto con su histograma:

\begin{itemize}
	\item Media: -0.07134
	\item Mediana: -0.1565
	\item Desviación típica: 0.6039855
	\item Rango: [-1.68,1.396]
	\item Primer y tercer cuartiles: (-0.548,0.371)
	\item Asimetría: 0.294874
	\item Curtosis: -0.7644792
\end{itemize}

vemos que, a la luz de los resultados, existe una asimetría a la derecha de la distribución, que además es platicúrtica. Si observamos el histograma

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{dist-F9.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Histograma de la variable F9} 
	\label{fig:hist-F9}
\end{figure}

como se puede ver, en la distribución de hombres existe una asimetría por la derecha (0.9905848) y para las mujeres, uno por la izquierda (-0.3907809), por lo que vemos la gran disparidad entre ambas distribuciones. \\

Comprobamos ahora la normalidad de la distribución:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{sw-F9.png}
		\caption{Shapiro-Wilk}
		\label{fig:sw-F9}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{l-F9.png}
		\caption{Lilliefors}
		\label{fig:l-F9}
	\end{subfigure}
	\caption{Tests de normalidad sobre F9}
	\label{fig:normF9}
\end{figure}

Ambos tests nos indican que debemos rechazar la hipótesis de normalidad.

Estudiamos ahora los boxplots.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bps9.png}
		\caption{Por sexo}
		\label{fig:bps9}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{bpsn9.png}
		\caption{Por interlocutor}
		\label{fig:bpsn9}
	\end{subfigure}
	\caption{Boxplot para F9 estudiando sexos e interlocutores}
	\label{fig:bf9}
\end{figure}

vemos apenas presencia de outliers aunque sí resultados muy dispares entre hombres y mujeres, e incluso dentro de los mismos sexos. \\


Si estudiamos la distribución de los hombres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swh-F9.png}
		\caption{Shapiro-Wilk}
		\label{fig:swh-F9}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lh-F9.png}
		\caption{Lilliefors}
		\label{fig:lh-F9}
	\end{subfigure}
	\caption{Tests de normalidad sobre F9 (hombres)}
	\label{fig:normhF9}
\end{figure}

vemos que debemos rechazar la hipótesis de normalidad. Por parte de las mujeres

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{swm-F9.png}
		\caption{Shapiro-Wilk}
		\label{fig:swm-F9}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.6\linewidth]{lm-F9.png}
		\caption{Lilliefors}
		\label{fig:lm-F9}
	\end{subfigure}
	\caption{Tests de normalidad sobre F9 (mujeres)}
	\label{fig:normmF9}
\end{figure}

también rechazamos la hipótesis de normalidad.

\subsubsection{Correlación entre variables}

Para estudiar la correlación entre las variables, en primer lugar, hago la representación de todas las variables, tomadas dos a dos, mostrando debajo de la diagonal, el scatter plot de las variables con un ajuste lineal. Por encima de la diagonal, vemos el valor de correlación de dichas variables con el nivel de significancia vía estrellas (p-valores(0, 0.001, 0.01, 0.05, 0.1, 1) <=> símbolos(“***”, “**”, “*”, “.”, " “)).

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{plot-vowel.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Comparativa de las variables dos a dos} 
	\label{fig:plot-vowel}
\end{figure}

Como podemos ver, la máxima correlación (negativa) es -0.53 entre las variables F3-F6 y F4-F8. Las demás son tendencias vagas. \\

Visto de otra manera, tenemos este gráfico

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.75]{vowel-flatten.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Comparativa de las variables dos a dos} 
	\label{fig:plot-vowel1}
\end{figure}
 
 \newpage
Si ahora introducimos la distinción entre hombres y mujeres, obtenemos los siguientes resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.75]{hombres-flatten.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Comparativa de las variables dos a dos (hombres)} 
	\label{fig:hombres-vowel1}
\end{figure}

donde aparecen nuevas correlaciones (positivas) entre F2-F9, F2-F8, F1-F8 y nuevas negativas F2-F5, F2-F0,F1-F4,F1-F5, F1-F0, F8-F4 o F8-F5 con valores cercanos a $\pm 0.48$. 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{hombres-plot.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Comparativa de las variables dos a dos (hombres)} 
	\label{fig:hombres-vowel}
\end{figure}

\newpage

Para las mujeres

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.75]{mujeres-flatten.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Comparativa de las variables dos a dos (mujeres)} 
	\label{fig:mujeres-vowel1}
\end{figure}

Por tanto, vemos una vez más que es útil hacer diferenciación por sexos para encontrar correlaciones entre variables.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{mujeres-plot.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Comparativa de las variables dos a dos (mujeres)} 
	\label{fig:mujeres-vowel}
\end{figure}
encontramos grandes correlaciones negativas entre F6-F3 (-0.68), F1-F3 (-0.68) o F7-F9 (-0.63).

\subsubsection{Conclusiones}

El conjunto de datos Vowel, visto en su totalidad, parece tener poco sentido desde el punto de vista estadístico, dando lugar a variables sin mucha relación entre ellas. Sin embargo, la existencia de la variable Sexo genera dos nuevos conjuntos de datos independientes donde sí encontramos variables correladas y distribuidas según una normal. Por otra parte, cada variable tiene un rango y un dominio distinto, por lo que es necesario hacer un reescalado para que todas estén en el mismo rango de valores. A partir de ahí, debido a la asimetría y curtosis de cada característica, podría ser posible aplicar transformaciones de tipo raíz cuadrada o logaritmo para así conseguir más normalidad en las variables. \\

Por otra parte, encontramos patrones de outliers en ciertos interlocutores. Es el caso del interlocutor 2, que presenta en las variables F3, F4, F6, F7 y F9; o el 11, en la F2,F5,F7 y F9. Podríamos llegar a pensar que, si cada variable es una medida de parámetros o características lingüísticas, esos interlocutores pueden tener una forma propia de hablar o algún problema de dicción. \\

Como se ha podido ver durante este desarrollo, las variables numéricas que tenemos no tienen ningún tipo de explicación ni justificación. Parecieran, a priori, valores descontextualizados, probablemente fruto de transformaciones matemáticas o salidas de instrumentos de medición como micrófonos o amplificadores. En consecuencia, no he podido establecer ninguna suerte de hipótesis, como sí hicimos en regresión. Para terminar el análisis exploratorio de datos, me gustaría enfatizar qué variables son interesantes para marcar fronteras de decisión entre las distintas clases de nuestro problema. Como viene siendo habitual, estudiar esto con el conjunto de datos completo no tiene unos resultados muy concluyentes. Sin embargo, si volvemos a separar por sexos, vemos que algunas variables pueden ser claramente determinantes en la distinción entre clases, dando que sus rangos de valores son disjuntos. Veámoslo con más detalle mediante boxplots:

\begin{itemize}
	\item \textbf{Hombres.}
	\begin{itemize}
		\item F0 y F1.
		
		\begin{figure}[H]
			\centering
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.9\linewidth]{bphF0.png}
				\caption{F0 vs Clases}
				\label{fig:bphF0}
			\end{subfigure}%
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.9\linewidth]{bphF1.png}
				\caption{F1 vs Clases}
				\label{fig:bphF1}
			\end{subfigure}
			\caption{Boxplot para F0 y F1}
			\label{fig:bph01}
		\end{figure}
	
	Podemos ver que la variable F0 es útil para separar las clases 3,6,8 o 9 mientras que puede ser confusa para la 0 o la 1 porque sus valores se solapan en exceso. Además, apenas presenta outliers, centrados en las clases 4,5 y 7. En el caso de F1, se pueden separar fácilmente las clases 0, 2, 4 o 10, mientras que la 8 y 9 se solapan mucho y la 3 presenta bastantes outliers en el rango de la clase 2, por lo que puede ser confusa. 
	\newpage
	\item F2 y F3.
	
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF2.png}
			\caption{F2 vs Clases}
			\label{fig:bphF2}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF3.png}
			\caption{F3 vs Clases}
			\label{fig:bphF3}
		\end{subfigure}
		\caption{Boxplot para F2 y F3}
		\label{fig:bph23}
	\end{figure}

	En el caso de la variable F2, se podrían diferenciar las clases 2 o 3 de la 7 fácilmente (a pesar de los outliers para la variable 7). Las demás presentan algunas diferencias pero todas se centran más o menos en un rango de una unidad. Para F3, la clase 0 y 2 se separan muy bien, de la misma forma que la 0 y la 4. 0 y 8 no por la gran cantidad de outliers en la clase 8. Por el contrario, vemos como las clases 6 y 7 tienen valores prácticamente iguales en esta variable y, como el rango es amplio, engloban muchas otras clases menores en el mismo.
	
		\item F4 y F5.
	
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF4.png}
			\caption{F4 vs Clases}
			\label{fig:bphF4}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF5.png}
			\caption{F5 vs Clases}
			\label{fig:bphF5}
		\end{subfigure}
		\caption{Boxplot para F4 y F5}
		\label{fig:bph45}
	\end{figure}

	Para la variable F4, las clases 1 y 4, 1 y 8 se diferencian bien, al idual que la 4 y la 9. La 7 es la más distante a todas a pesar del outlier que presenta, aunque todas las clases se encuentran en un rango bastante reducido. Por su parte, la variable F5 parece ser estupenda para separar. Como vemos, hay dos franjas de clases, las que toman valores aproximadamente por encima de 1.0 y las que toman valores menores. Por tanto, se presentan buenas oportunidades de encontrar diferencias, por ejemplo, entre las clases 1 y 7.
	
	\item F6 y F7.
	
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF6.png}
			\caption{F6 vs Clases}
			\label{fig:bphF6}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF7.png}
			\caption{F7 vs Clases}
			\label{fig:bphF7}
		\end{subfigure}
		\caption{Boxplot para F6 y F7}
		\label{fig:bph67}
	\end{figure}

	Como se puede observar, la variable F6 tiene un rango de valores muy parejo para las variables. Tan sólo podemos saber que la clase 6 es la única que toma valores por debajo de -0.5, por lo que podría ser una posible distinción. F7, del mismo modo, apenas tiene diferencias entre las clases. Hay que subrayar la presencia de outliers para la clase 6 y la 7, lo que dificulta aún más la separación.
	\newpage
	\item F8 y F9.
	
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF8.png}
			\caption{F8 vs Clases}
			\label{fig:bphF8}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{bphF9.png}
			\caption{F9 vs Clases}
			\label{fig:bphF9}
		\end{subfigure}
		\caption{Boxplot para F8 y F9}
		\label{fig:bph89}
	\end{figure}

	La variable F8, por el contrario, es estupenda para separar entre sí las clases 2,3 y 4; 1,3,4; 3 y 7; 3 y 8. Otras se solapan, como la 8, 9 y 10  o la 4 y 5. Por el contrario, la variable F9 nos lo pone más difícil, con solapamiento en prácticamente todas las clases a excepción de la 3 y 7 o 9, cuya separación podría ser de utilidad.
	\end{itemize}
	
	\item \textbf{Mujeres.}
	
	\begin{itemize}
		\item F0 y F1
		
		\begin{figure}[H]
			\centering
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.9\linewidth]{bpmF0.png}
				\caption{F0 vs Clases}
				\label{fig:bpmF0}
			\end{subfigure}%
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.9\linewidth]{bpmF1.png}
				\caption{F1 vs Clases}
				\label{fig:bpmF1}
			\end{subfigure}
			\caption{Boxplot para F0 y F1}
			\label{fig:bpm01}
		\end{figure}
		
		Para la variable F0, las clases 0 y 3, 0 y 4, 0 y 5, 0 y 6, 1 y 2, 1 y 4, 1 y 5 u 9 y 10 son fácilmente separables. Por otro lado, las clases 2,3,4 y 5, 6 y 10, 7 y 8 (a pesar de outliers) se solapan. F1, por el contrario, es una estupenda variable para separar clases como 1 y 4,5,6,7,8 o 10. 
		
		\item F2 y F3.
		
		\begin{figure}[H]
			\centering
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF2.png}
				\caption{F2 vs Clases}
				\label{fig:bpmF2}
			\end{subfigure}%
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF3.png}
				\caption{F3 vs Clases}
				\label{fig:bpmF3}
			\end{subfigure}
			\caption{Boxplot para F2 y F3}
			\label{fig:bpm23}
		\end{figure}
	
		En la variable F2, los intervalos para cada clase van disminuyendo muy progresivamente, por lo que separa las clases 0 con 2,3,4,5,6 (salvo el outlier), 7 y 10. Por ejemplo, las clases 3,4,5,6 y 7 se solapan, por lo que esta variable no es conveniente para separarlas entre sí. En la variable F3, las clases 0, 1 y 2 se solapan en valores, al igual que las 8, 9 y 10. Sin embargo, las tres primeras están en el entorno de 1.5 y las demás toman valores menores, por lo que son separables por pares salvo con la clase 7, cuya abundante cantidad de outliers hace que pudiera confundirse con las clases 0,1 o 2.
		\newpage
		\item F4 y F5.
		
		\begin{figure}[H]
			\centering
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF4.png}
				\caption{F4 vs Clases}
				\label{fig:bpmF4}
			\end{subfigure}%
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF5.png}
				\caption{F5 vs Clases}
				\label{fig:bpmF5}
			\end{subfigure}
			\caption{Boxplot para F4 y F5}
			\label{fig:bpm45}
		\end{figure}
	
		La variable F4, a pesar de concentrar gran número de outliers en las clases 2, 3, 9 y 10, puede resultar muy útil para separar las clases 0 con 4 ,5, 6,7 y 8, al igual que 1 con con 4 ,5, 6,7 y 8. F5, por su parte, podría servir para separar las clases 2 con 4 y 8, al igual que la 3. Sin embargo, la gran mayoría de las clases se solapan en los valores por ser una variable muy concentrada (2 unidades).
		
		\item F6 y F7.
		
		\begin{figure}[H]
			\centering
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF6.png}
				\caption{F6 vs Clases}
				\label{fig:bpmF6}
			\end{subfigure}%
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF7.png}
				\caption{F7 vs Clases}
				\label{fig:bpmF7}
			\end{subfigure}
			\caption{Boxplot para F6 y F7}
			\label{fig:bpm67}
		\end{figure}
		
		El variable F6, la clase 1 se separa de todas excepto de la 0 y la 2. Sin embargo, el resto se solapan. En la variable 7, encontramos un grupo de clases que se agolpan bajo el 0.0 (de la 0 a la 5) y otras que están por encima de 0.0 (6 a 10), por lo que son fácilmente separables entre grupos y se solapan entre grupos.
		
		\item F8 y F9.
		
		\begin{figure}[H]
			\centering
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF8.png}
				\caption{F8 vs Clases}
				\label{fig:bpmF8}
			\end{subfigure}%
			\begin{subfigure}{.5\textwidth}
				\centering
				\includegraphics[width=.8\linewidth]{bpmF9.png}
				\caption{F9 vs Clases}
				\label{fig:bpmF9}
			\end{subfigure}
			\caption{Boxplot para F8 y F9}
			\label{fig:bpm89}
		\end{figure}
	
		La variable F8 no es buena para separar ninguna clase en especial, dado que se solapan prácticamente los valores entorno al 0.5. Por el contrario, la variable F9 separa bien las clases 0,1,2,3,4 y 6,7,8 y 9. 0,1,2,3,4,5 y 10 se solapan, al igual que 6,7,8 y 9.
	\end{itemize}

\end{itemize}

\newpage
%----------------------------------------------------------------------------------------
%	Regresión
%----------------------------------------------------------------------------------------

\section{Problema de regresión: Wankara}

Tras realizar el análisis exploratorio de datos sobre el conjunto de datos Wankara, estamos en condiciones de abordar el problema de regresión, es decir, encontrar y ajustar un modelo que prediga bien la variable Mean temperature. Dicho trabajo estará dividido en cuatro secciones, que coinciden con los puntos exigidos en el trabajo. El primero tratará de ajustar y comparar modelos lineales simples con los 5 regresores más interesantes. El segundo, crear modelos lineales más complejos combinando distintos regresores, utilizando interacciones y combinaciones no lineales. En la tercera, ajustamos un modelo kNN y en el último hacemos una comparación de los algoritmos incorporando los resultados obtenidos en la fila de Wankara.

\subsection{Regresión lineal simple sobre 5 regresores}

Como Wankara tiene más de 5 variables, elijo las 5 más representativas para la predicción de Mean temperature. En otras palabras, aquellas que tienen una correlación mayor (vista en el EDA): Max-temperature, Min-temperature, Dewpoint, Sea-level-pressure y Visibility. Antes de aplicar ajustar cualquier modelo, reescalo las variables de Wankara para que todas estén en el mismo rango (y así evitar sesgos hacia las que tienen un rango de valores mayor). Para todas ellas, el procedimiento será el mismo. Entreno un modelo lineal con todo el conjunto a través del regresor elegido, muestro la recta obtenida y el error cuadrático medio. Para validar estos resultados, llevo a cabo una validación cruzada con 5 particiones y calculo el error cuadrático medio en training y test.

\subsubsection{Modelo con Max-temperature}

El modelo generado es el siguiente:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.735]{lm1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Max-temperature} 
	\label{fig:lm1}
\end{figure}

Con un $R^2$ ajustado de 0.9456 y un error cuadrático medio de $0.04876785$. El siguiente scatter plot muestra el resultado del ajuste:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.735]{plot1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Max-temperature. Scatter plot} 
	\label{fig:plot1}
\end{figure}

Tras realizar la validación cruzada, obtenemos un error cuadrático medio en training de 12.98672 y en test de 13.00239.

\subsubsection{Modelo lineal con Min-temperature}

Entrenamos un segundo modelo lineal con la variable Min-temperature. Este es el resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.735]{lm2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Min-temperature} 
	\label{fig:lm2}
\end{figure}

que nos deja un $R^2$ ajustado de 0.8775 y un error cuadrático medio de $0.07315107$. Podemos verlo gráficamente como sigue.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.735]{plot2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Min-temperature. Scatter plot} 
	\label{fig:plot2}
\end{figure}

Podemos ver que el ajuste no es tan bueno como el anterior, dado que la nube de puntos es más ancha y se separa algo más de la recta obtenida. Tras la validación cruzada de 5 particiones, obtenemos un error cuadrático medio en training de $29.21725$ y en test de $29.27856$. La diferencia tan pequeña del error en entrenamiento y test indica que no existe sobreajuste y la generalización ha sido buena. 

\subsubsection{Modelo lineal con Dewpoint}

Entrenamos un tercer modelo lineal con Dewpoint. Este es el resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.55]{lm3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Dewpoint} 
	\label{fig:lm3}
\end{figure}

con un $R^2$ ajustado de $0.8035$  y un error cuadrático medio de $0.09265712$. Gráficamente vemos cómo se ajusta esta recta a los puntos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.55]{plot3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Dewpoint. Scatter plot} 
	\label{fig:plot3}
\end{figure}

El ajuste va bajando en calidad conforme pasamos avanzamos en los modelos. Tras la validación cruzada de 5 particiones, obtenemos un error cuadrático medio en training de $46.88105$ y en test de $46.93901$, con pequeñas diferencias entre ellos también.

\subsubsection{Modelo lineal con Sea level pressure}

Cuarto modelo lineal, ahora con la variable Sea level pressure. El resultado es el siguiente:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.55]{lm4.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Sea level pressure} 
	\label{fig:lm4}
\end{figure}

con un $R^2$ ajustado de $0.4118$  y un error cuadrático medio de $0.1603035$. Gráficamente vemos cómo se ajusta esta recta a los puntos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.55]{plot4.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Sea level pressure. Scatter plot} 
	\label{fig:plot4}
\end{figure}

El ajuste ha empeorado mucho con esta variable. Tras la validación cruzada de 5 particiones, obtenemos un error cuadrático medio en training de $140.3178$ y en test de $140.5083$

\subsubsection{Modelo lineal con Visibility}

Último modelo lineal con una variable, en este caso Visibility. Este es el resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.55]{lm5.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Visibility} 
	\label{fig:lm5}
\end{figure}

con un $R^2$ ajustado de $0.2345$  y un error cuadrático medio de $0.1828792$. Gráficamente vemos cómo se ajusta esta recta a los puntos:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.55]{plot5.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal con Visibility. Scatter plot} 
	\label{fig:plot5}
\end{figure}

Tras la validación cruzada de 5 particiones, obtenemos un error cuadrático medio en training de $182.5684$ y en test de $183.3558$

\subsubsection{Conclusiones}

Partimos de una tabla resumen para sacar las conclusiones del estudio anterior.

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		& $R^2$ ajustado & MSE        & \begin{tabular}[c]{@{}c@{}}CV 5fold\\ MSE train(media)\end{tabular} & \begin{tabular}[c]{@{}c@{}}CV 5fold\\ MSE test(media)\end{tabular} \\ \hline
		Max-temperature    & 0.9456         & 0.04876785 & 12.98670                                                            & 13.00239                                                           \\ \hline
		Min-temperature    & 0.8775         & 0.07315107 & 29.21725                                                            & 29.27856                                                           \\ \hline
		Dewpoint           & 0.8035         & 0.09265712 & 46.88105                                                            & 46.93901                                                           \\ \hline
		Sea level pressure & 0.4118         & 0.1603035  & 140.3178                                                            & 140.5083                                                           \\ \hline
		Visibility         & 0.2345         & 0.1828792  & 182.5684                                                            & 183.3558                                                           \\ \hline
	\end{tabular}
	\caption{Resumen de resultados para modelos lineales simples}
\end{table}

Como elegimos los regresores en función de la correlación, es evidente que aquellos que están más correlacionados con Mean temperature obtienen valores de $R^2$ ajustado más alto y MSE más pequeño. Una gran diferencia entre el MSE sobre todo el conjunto de datos y la media en training y test de la validación cruzada, la cual se justifica debido a la cantidad de datos que tiene un modelo y otro: mientras que el primero se realiza con todos los datos, lo que le da un gran poder de aprendizaje, el segundo se hace sobre un quinto de los datos cada vez y luego se calcula la media de los resultados. Aún así, vemos que la diferencia entre entrenamiento y test es muy pequeña, lo que nos indica que nuestro modelo está generalizando correctamente y no hay sobreajuste. Por supuesto, en virtud del valor de $R^2$ ajustado y los MSE, el modelo lineal basado en Max temperature es el más potente para predecir el valor de Mean temperature. 

\subsection{Modelos lineales múltiples. Interacciones y no linealidad}

Una vez explorados los 5 modelos lineales con un solo regresor. Enfrentamos ahora el problema con regresión múltiple. Dado que tenemos 9 regresores, por eficiencia elijo hacerlo con el llamado Backward Model, es decir, partiendo de todos los regresores e ir eliminando los regresores menos significativos. Nuestro objetivo es doble: el primero es encontrar un modelo competitivo y a la vez explicable (\cite{aiexpl}); el segundo, encontrar un modelo con el mayor $R^2$ ajustado posible. Para el primer objetivo, utilizamos backward model; para el segundo, interacciones y no linealidad.

\subsubsection{Hacia un modelo competitivo y explicable}

Partimos de un modelo lineal con los 9 regresores. Obtenemos este resultado:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple con todas las variables} 
	\label{fig:mlm1}
\end{figure}

Obtenemos un $R^2$ ajustado de 0.9898 y 1599 grados de libertad. Mirando los p-valores de los regresores, vemos uno, el de Precipitation, de 0.885, por lo que no es relevante en el ajuste. Siendo así, la eliminamos y generamos un nuevo modelo:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple sin Precipitation} 
	\label{fig:mlm2}
\end{figure}

Como vemos, el error residual ha disminuido, el $R^2$ ajustado se mantiene y ganamos un grado de libertad, 1600, por lo que ha sido acertado eliminar esa variable. Todos los p-valores ahora son bastante pequeños, así que eliminamos la variable que tenga mayor error estándar, es decir, Sea level pressure:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple sin Precipitation y Sea level pressure} 
	\label{fig:mlm3}
\end{figure}

Este modelo disminuye muy ligeramente el $R^2$ ajustado (0.9893) y aumenta el error residual (0.02163). Sin embargo, la disminución es tan pequeña que merece la pena eliminar una variable y ganar interpretabilidad. Seguimos en la misma dinámica y elimino el regresor con un error estándar elevado (aunque no el mayor, que es Dewpoint), Max wind speed. No elimino Dewpoint porque antes vimos que está muy correlacionada con Mean temperature, lo que sospecho nos puede hacer bajar demasiado el $R^2$ ajustado.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm4.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple sin Precipitation, Sea level pressure, Max wind speed} 
	\label{fig:mlm4}
\end{figure}

Como resultado de la eliminación de Max wind speed, disminuimos 3 diezmilésimas el $R^2$ ajustado (0.98) y el error residual aumenta apenas nada. Visibility es la siguiente variable a eliminar, que tiene el mayor p-valor en general y mayor error estándar de entre las poco correladas:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm5.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple sin Precipitation, Sea level pressure, Max wind speed, Visibility} 
	\label{fig:mlm5}
\end{figure}

Volvemos a perder una diezmilésima en el $R^2$ ajustado (0.9889), aún sigue siendo un resultado muy bueno (apenas hemos perdido una centésima) quitando cuatro regresores. La siguiente en eliminarse es

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm6.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple sin Precipitation, Sea level pressure, Max wind speed, Visibility, Standard Pressure} 
	\label{fig:mlm6}
\end{figure}

El resultado vuelve a ser favorable, 0.9886. Por último, para encontrar el modelo más interpretable, con las variables que más sentido podemos darle respecto de la temperatura media, eliminamos Wind speed.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{mlm7.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Modelo lineal múltiple más interpretable: Max temperature, Min temperature y Dewpoint} 
	\label{fig:mlm7}
\end{figure}

Hemos perdido un par de centésimas desde un modelo con nueve regresores a uno con 3, con $R^2$ ajustado 0.9879, 1605 grados de libertad y un error residual de 0.02301. Además, esos tres regresores son semánticamente muy relevantes con el problema, ya que están basados en las hipótesis que comenté en el EDA e incluyen Dewpoint, una variable que también tiene que ver con la temperatura, para explicar la temperatura media. Por tanto, hemos cumplido nuestro primer objetivo en regresión lineal múltiple.

\subsubsection{Modelo lineal múltiple óptimo: interacciones y no linealidad}

 El proceso de búsqueda del modelo lineal múltiple óptimo tiene mucho de eso, de proceso de búsqueda. Muchas veces la heurística y la intuición van de la mano hasta encontrar algo satisfactorio. Parece lógico pensar que hay que enfatizar aquellas variables que sean más importantes (las del modelo más interpretable anterior), eliminar las que apenas aportan nada y combinar las que pueden tener una relación desde el punto de vista semántico. He pasado por siete modelos  (pueden verse en el código del apéndice II), líneas 480-506 con distintas aproximaciones. En el primero, busco la interacción entre Sea level pressure y Standard pressure y elimino Precipitation con resultado 0.9899. En el segundo, elimino Precipitation e interacciono Min-temperature y Dewpoint, con resultado 0.9899 (sin mejora). En el tercero, elimino Precipitation y Dewpoint (tienen un p-valor de 0.99 si lo mantengo), interacciono Dewpoint y Min-temperature y elevo al cuadrado Dewpoint con resultado 0.99. Observo que en el resultado del tercero, Visibility es poco representativo, por lo que en el cuarto mantengo lo anterior y elimino Visibility, con resultado 0.9899, empeorando. En el quinto, añado el término de Max-temperature al cuadrado y mantengo Visibility, con resultado 0.9918 (mejor hasta el momento). En el sexto, elevo al cuadrado también Min-temperature, con resultado 0.9923 (mejorando el anterior). Para evitar la redundancia por la interacción entre Max wind speed y Wind speed, elimino Max wind speed obteniendo el mismo 0.9923, como definitivo modelo óptimo. He aquí el resultado:
 
 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
 	\centering
 	\includegraphics[scale=0.5]{optimo.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
 	\caption{Modelo lineal múltiple óptimo} 
 	\label{fig:optimo}
 \end{figure}

$R^2$ ajustado de 0.9923, 1597 grado de libertad y error residual de 0.01837. El error cuadrático medio cometido es 0.01830154. Podemos ver gráficamente el resultado obtenido:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{plot-opt.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Plot del modelo óptimo encontrado sobre la gráfica Max-temperature-Mean-temperature} 
	\label{fig:plot-opt}
\end{figure}

Como se ve, se cubre gran parte de los puntos. Llevamos a cabo una validación cruzada de siete particiones para garantizar los resultados. Se comete un error cuadrático medio en training de  1.848325 y en test de 1.784818, por lo que vemos que el modelo no sobreajusta y funciona de manera satisfactoria. \\

No cabe duda de que los modelos lineales múltiples, introduciendo interacciones y no linealidades mejoran los resultados del apartado anterior, si bien se pierde interpretabilidad. Mi opción es siempre dar las dos facetas: el modelo interpretable más útil en términos de ajuste y una opción óptima, menos interpretable pero que gana, en este caso, una centésima en rendimiento. 

\subsection{kNN en regresión}

Ajustamos ahora un modelo kNN. Lo hago de tres formas distintas: la primera, con todos los regresores; la segunda, con el modelo óptimo obtenido en el apartado anterior; la tercera, con el modelo más interpretable. \\

\begin{itemize}
	\item \textbf{kNN con todos las variables.}
	
	Aplico kNN con todas las variables y este es el resultado:
	
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.5]{knn1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Primera aproximación: knn con todas las variables} 
		\label{fig:knn1}
	\end{figure}
	
	El error cuadrático medio cometido es 0.02173683
	
	\item \textbf{kNN con la combinación óptima (para el modelo lineal) de las variables}
	
	Rescato la combinación para que esté clara:
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.5]{fitknn2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Segunda aproximación: knn con la combinación óptima anterior. Modelo} 
		\label{fig:fitknn2}
	\end{figure}

	El resultado es el siguiente:
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.5]{knn2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Primera aproximación: knn con la combinación óptima anterior} 
		\label{fig:knn2}
	\end{figure}

	El error cuadrático medio cometido es 0.01609035, por lo que este modelo es mejor que kNN con todas las variables.
	
	\item \textbf{kNN con el modelo lineal más interpretable.}
	
	El modelo lineal más interpretable era el que sólo incluía Max temperature, Min temperature y Dewpoint como regresores. El resultado es el siguiente:
	
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.5]{knn3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Primera aproximación: knn con la combinación más interpretable} 
		\label{fig:knn3}
	\end{figure}
	
	El error cuadrático medio cometido es 0.01461469, aún menor que con la combinación óptima del modelo lineal, por lo que vemos que el modelo lineal y kNN varían en sus resultados. 
\end{itemize} 

	En resumen, confirmamos que las combinaciones de regresores para kNN y el modelo lineal obtienen diferentes salidas y que, por ahora, para kNN, la interpretabilidad pesa más que la optimalidad con interacciones y términos no lineales.

\subsection{Comparación con algoritmos}

Llegamos a la última sección de regresión: comparación de algoritmos. En este caso, la llevo a cabo de dos formas. En la primera, realizo una validación cruzada de 5 particiones con el modelo lineal y kNN, ambos dos formados por todos los regresores. Calculo la media del error cuadrático medio para entrenamiento y test y almaceno esos resultados en los ficheros csv cedidos en PRADO. A continuación, realizo los test de Wilcoxon por pares y el de Friedman con Post-Hoc Holm para ver si hay diferencias significativas entre los algoritmos evaluados en los distintos datasets. \\
Por otro lado, supongo las 5 particiones cedidas para la validación cruzada como distintos conjuntos de datos y hago una comparación sobre los resultados de los modelos lineal, kNN y Random Forest para ver si hay diferencias significativas exclusivamente en el dataset Wankara.

\subsubsection{Comparativa sobre los distintos datasets}

\begin{itemize}
	\item \textbf{Test}
		Tras realizar la validación cruzada para el modelo lineal y kNN e incorporar los errores al csv, los resultados de los algoritmos en test son los siguientes:
		\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
			\centering
			\includegraphics[scale=0.6]{tablatst-R4.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
			\caption{Tabla de MSE para cada algoritmo sobre los conjuntos} 
			\label{fig:tablatst-R4}
		\end{figure}
	
		A continuación, aplico el test de Wilcoxon por parejas.
		\begin{itemize}
			\item LM (other) vs kNN (reference)
			Los resultados son los siguientes:
			
			\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
				\centering
				\includegraphics[scale=0.6]{lmknn1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
				\caption{Test de Wilcoxon: LM vs KNN} 
				\label{fig:lmknn1}
			\end{figure}
			No hay diferencias significativas (p-valor 0.7660294), ya que solo hay un 23.39706\% de confianza de que sean distintos.
		
			\item LM (other) vs M5P (reference)
			Los resultados son los siguientes:
			\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
				\centering
				\includegraphics[scale=0.6]{lmm5p1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
				\caption{Test de Wilcoxon: LM vs M5P} 
				\label{fig:lmm5p1}
			\end{figure}
		
			Hay diferencias significativas con un 99.8420715\% de confianza.
			
			\item kNN (other) vs M5P (reference)
			Los resultados son los siguientes:
			\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
				\centering
				\includegraphics[scale=0.6]{knnm5p1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
				\caption{Test de Wilcoxon: kNN vs M5P} 
				\label{fig:knnm5p1}
			\end{figure}
			No se pueden asumir diferencias significativas, ya que sólo tenemos un 83.26492\% de confianza de que sean distintos.
		\end{itemize}
		Si aplicamos el test de Friedman
		
		\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
			\centering
			\includegraphics[scale=0.6]{friedman1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
			\caption{Test de Friedman} 
			\label{fig:friedman1}
		\end{figure}
		
		y el Post Hoc Holm 
		
		\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
			\centering
			\includegraphics[scale=0.6]{ph1.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
			\caption{Post-hoc holm} 
			\label{fig:ph1}
		\end{figure}
		vemos que hay diferencias significativas entre M5P y LM favorables a M5P (0.081) y entre M5P y kNN (0.108) con aproximadamente un 90\% de confianza, mientras que LM y kNN pueden suponerse iguales.
		
	\item \textbf{Train}
	
	Evalúo ahora los resultados de training, para encontrar posibles sobreajustes. Trabajo de la misma manera: primero Wilcoxon por parejas y después Friedman:
	
	\begin{itemize}
		\item LM (other) vs kNN (reference)
		Los resultados son los siguientes:
		
		\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
			\centering
			\includegraphics[scale=0.6]{lmknn2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
			\caption{Test de Wilcoxon: LM vs KNN} 
			\label{fig:lmknn2}
		\end{figure}
		Hay diferencias significativas (p-valor 0.000328064), con una confianza del 99\%.
		
		\item LM (other) vs M5P (reference)
		Los resultados son los siguientes:
		\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
			\centering
			\includegraphics[scale=0.6]{lmm5p2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
			\caption{Test de Wilcoxon: LM vs M5P} 
			\label{fig:lmm5p2}
		\end{figure}
		
		Hay diferencias significativas con más de un 99\% de confianza.
		
		\item kNN (other) vs M5P (reference)
		Los resultados son los siguientes:
		\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
			\centering
			\includegraphics[scale=0.6]{knnm5p2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
			\caption{Test de Wilcoxon: kNN vs M5P} 
			\label{fig:knnm5p2}
		\end{figure}
		Hay diferencias significativas con un 99\% de confianza.
	\end{itemize}
	Si aplicamos el test de Friedman
	
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.6]{friedman2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Test de Friedman} 
		\label{fig:friedman2}
	\end{figure}
	
	y el Post Hoc Holm 
	
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.6]{ph2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Post-hoc holm} 
		\label{fig:ph2}
	\end{figure}
	
	Se puede considerar que todos los algoritmos son estadísticamente diferentes con el mismo intervalo de confianza (99.7\% aprox.). Como se puede ver, el comportamiento en training y test puede sugerir sobreajuste o que los datos son erróneos.
\end{itemize}
 
 
\subsubsection{Comparativa sobre los folds de Wankara}

Tras ejecutar el modelo lineal, kNN y Random Forest con una validación cruzada de 5 particiones del dataset Wankara, obtenemos en test los siguientes errores cuadráticos medios:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{tablatst2.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Tabla resultados en test para los folds} 
	\label{fig:tablatst2}
\end{figure}

Aplico ahora los tests de Wilcoxon y Friedman para terminar. 

\begin{itemize}
	\item LM (other) vs kNN (reference)
	Los resultados son los siguientes:
	
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.6]{lmknn3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Test de Wilcoxon: LM vs KNN} 
		\label{fig:lmknn3}
	\end{figure}
	Hay diferencias significativas con un 93.75\% de confianza
	
	\item LM (other) vs M5P (reference)
	Los resultados son los siguientes:
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.6]{lmrf3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Test de Wilcoxon: LM vs RF} 
		\label{fig:lmrf3}
	\end{figure}
	
	Hay diferencias significativas con un 93.75\% de confianza
	
	\item kNN (other) vs RF (reference)
	Los resultados son los siguientes:
	\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
		\centering
		\includegraphics[scale=0.6]{knnrf3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
		\caption{Test de Wilcoxon: kNN vs RF} 
		\label{fig:knnrf3}
	\end{figure}
	Hay diferencias significativas con un 93.75\% de confianza.
\end{itemize}

Si aplicamos el test de Friedman

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{friedman3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test de Friedman} 
	\label{fig:friedman3}
\end{figure}

y el Post Hoc Holm 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{ph3.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Post-hoc holm} 
	\label{fig:ph3}
\end{figure}

Vemos que de forma conjunta, no podemos asegurar que sean distintos porque sólo contamos con un 81\% de confianza en ello.
\newpage
%----------------------------------------------------------------------------------------
%	Clasificación
%----------------------------------------------------------------------------------------


\section{Problema de clasificación: Vowel}

Comenzamos con el estudio de clasificación para el conjunto de datos Vowel. Esta sección constará de cuatro partes: la primera dedicada al algoritmo KNN; la segunda, a LDA; la tercera, a QDA; por último, realizo una comparación entre los algoritmos nombrados. Dicha comparación se hace gracias a la ejecución de los mismos sobre 5 particiones previamente fijadas. Se almacena el accuracy de cada algoritmo y partición y se llevan a cabo los tests estadísticos de Wilcoxon (para el estudio por parejas de algoritmos) y el de Friedman, con Post-Hoc Holm para la comparación conjunta. Previa ejecución de cualquier algoritmo, las variables han sido escaladas para que la diferencia de rangos no afecte a los resultados. Además, sólo utilizo como variables predictivas las numéricas, obviando por el momento el sexo (para hacer distinciones) o el interlocutor.

\subsection{KNN}

Dentro del ejercicio 1 propuesto, se pide que se trabaje con distintos valores de k para el algoritmo kNN. En esta primera parte, sobre el conjunto de datos al completo, realizo un particionamiento training-test del 70\%-30\% para entrenar el algoritmo con distintos valores de k, desde 1 hasta 15. En la siguiente imagen podemos ver el rendimiento extraído:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{k-values.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Accuracy para los distintos valores de k} 
	\label{fig:k-values}
\end{figure}

A la luz de los resultados, elijo el valor de $k=3$ para continuar y ahora intento mostrar las fronteras de decisión entre clases, haciendo un plot con las variables, por ejemplo,, F0 y F1.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{boundaries-knn.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Plot F1-F2 para mostrar las fronteras de decisión} 
	\label{fig:boundaries-knn}
\end{figure}

o para F2 y F6

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{boundariesf2f6-knn.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Plot F2-F6 para mostrar las fronteras de decisión} 
	\label{fig:boundaries-knn-f2f6}
\end{figure}

Si realizamos la clasificación por sexos y el rendimiento respecto del valor de $k$, vemos que los resultados son algo distintos:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{knn-k-h.png}
		\caption{Evolución del accuracy y k para hombres}
		\label{fig:k-h}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{knn-k-m.png}
		\caption{Evolución del accuracy y k para mujeres}
		\label{fig:k-m}
	\end{subfigure}
	\caption{Valores de k vs Accuracy para hombres y mujeres}
	\label{fig:k-h-m}
\end{figure}

lo que nos muestra que, por separado, el resultado de la clasificación sería aún mejor. Por último, intento validar estos resultados con una validación cruzada de 10 particiones para ver los mejores valores de k tanto en training como en test. Primero, para training,

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{k-knn-10kf-tr.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Evolución de accuracy respecto de k en training} 
	\label{fig:k-knn-10kf-tr}
\end{figure}

donde los mejores valores son $k=1, k=3$. Para test,

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.8]{k-knn-10kf-tst.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Evolución de accuracy respecto de k en test} 
	\label{fig:k-knn-10kf-tst}
\end{figure}

donde vemos que los mejores valores se mantienen pero que caen a partir de $k=11$. Para la comparación de algoritmos, utilizo los valores de $k=1, k=3$ y almaceno el accuracy para cada partición. Además, a modo de resumen, calculo la media de los resultados en test para cada partición, obteniendo un $99.69697\%$.



\subsection{LDA}

Pasamos ahora a LDA. Previa a su implementación sobre el conjunto de datos, tenemos que comprobar que las variables siguen una distribución normal y todas tienen la misma varianza (\cite{regresion}).

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{shapiro-lda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Test de normalidad para cada variable} 
	\label{fig:shapiro-lda}
\end{figure}

Como vemos, las variables no siguen una distribución normal (ya lo vimos también en el EDA).

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{var-lda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Varianza de las variables} 
	\label{fig:var-lda}
\end{figure}

Podemos ver que las varianzas difieren en $\pm 0.02$ aproximadamente, por lo que tampoco se cumple esta condición. En consecuencia, los resultados de LDA no serán especialmente rigurosos. Primero, entrenamos un modelo generando una partición, con las mismas proporciones que en el caso de kNN, sobre nuestro conjunto de datos.  Veamos la matriz de confusión generada:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{cm-lda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Matriz de confusión para LDA} 
	\label{fig:cm-lda}
\end{figure}

y cuyas estadísticas generales son

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{statis-lda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Estadísticas generales para LDA} 
	\label{fig:statis-lda}
\end{figure}

El resultado, sobre la partición estratificada, es bastante pobre. Intentamos una visualización con la herramienta \textit{Partimat} sobre las variables F0, F1, F2 y F3:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{partimat-lda-v.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Partimat sobre F0-F3 para el modelo de LDA en Vowel} 
	\label{fig:partimat-lda-v}
\end{figure}

Si dividimos el dataset por sexos, a parte de que se consigue con mayor facilidad la normalidad (como ya vimos en EDA), los resultados mejoran mucho:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{cm-hombres.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Matriz de confusión para hombres LDA} 
	\label{fig:cm-hombres}
\end{figure}

Así también se refleja en las estadísticas

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{statis-hombres.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Estadísticas generales para hombres LDA} 
	\label{fig:statis-hombres}
\end{figure}

con un aumento del $20\%$ en accuracy. También mejora para el subconjunto de mujeres en un $15\%$:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{statis-mujeres.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Estadísticas generales para mujeres LDA} 
	\label{fig:statis-mujeres}
\end{figure}

Para validar, los resultados, llevo a cabo una validación cruzada de 10 particiones con predicciones sobre el conjunto de training como el de test, almacenándose el accuracy para cada partición y obteniéndose una media de $64.82604\%$ en training y  $60.30303\%$ en test.

\subsection{QDA}

A juzgar por los resultados de LDA, parece que las 11 clases de nuestro dataset son difícilmente separables con una función lineal. Sin embargo, una cuadrática pueda tener un mejor rendimiento. Es por eso que utilizamos ahora QDA. Como en LDA, necesitamos comprobar unas hipótesis. En este caso, QDA requiere que la varianza de los regresores sea igual en cada clase, aunque pueda ser distinta entre clases. Como se verá a continuación, esta hipótesis tampoco se va a cumplir (como en LDA), por lo que la capacidad de predicción de QDA se verá mermada.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{var1-qda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Varianza de los regresores entre las clases 0 y 4} 
	\label{fig:var1-qda}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{var2-qda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Varianza de los regresores entre las clases 4 y 8} 
	\label{fig:var2-qda}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{var3-qda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Varianza de los regresores entre las clases 9 y 10} 
	\label{fig:var3-qda}
\end{figure}

Ha quedado patente que no se cumple la hipótesis de QDA. Aún así, seguimos adelante en el estudio. Como en los algoritmos anteriores, realizamos una partición estratificada 70-30 para training/test y genero un modelo con QDA. Vemos que el resultado es notoriamente mejor. Primero, con la matriz de confusión

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{cm-qda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Matriz de confusión para QDA} 
	\label{fig:cm-qda}
\end{figure}

y cuyas estadísticas generales son

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{statis-qda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Estadísticas generales para QDA} 
	\label{fig:statis-qda}
\end{figure}

con un $87.54\%$ de accuracy. Sin embargo, la matriz de confusión da la sensación, al menos en la mayoría de las clases, que el rendimiento debería ser mayor. Veamos las estadísticas por clases

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.5]{statis-qda-c.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Estadísticas generales para QDA por clase} 
	\label{fig:statis-qda-c}
\end{figure}

donde vemos que todas las clases tienen un accuracy de más del $90\%$ excepto la 5, que tiene un $86.252\%$. Este hecho podría explicarse con que, como hemos visto antes, para el subconjunto de mujeres, la clase 5 presenta outliers en la mayoría de las variables. Vemos, como antes, una separación del espacio representado en las variables F0-F3:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.3]{partimat-qda.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Partimat sobre F0-F3 para el modelo de QDA en Vowel} 
	\label{fig:partimat-qda-v}
\end{figure}

lo que nos muestra la dificultad en la partición por clases. Por último, para validar los resultados, llevo a cabo una validación cruzada con las 10 particiones ofrecidas, de nuevo almacenando el accuracy de cada partición tanto en training como en test. El accuracy medio en train resulta $94.92705\%$ y en test, $91.0101\%$. Como estos resultados son satisfactorios, no hago la división por sexos como LDA. Sin embargo, casi con toda probabilidad obtendríamos un rendimiento mayor que con el conjunto total.

\subsection{Comparación de algoritmos en test}

Para terminar con el apartado de clasificación, procedemos a la comparación de algoritmos. Como se ha comentado, para cada una de las etapas anteriores se han almacenado los distintos accuracy en las particiones. Tras ejecutar todos los modelos, la tabla de resultados es la siguiente:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{tabla-resultados.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Tabla de resultados para cada algoritmo y partición} 
	\label{fig:tabla-res}
\end{figure}

Como se puede ver, en cada columna colocamos los modelos tratados: 1NN, 3NN, LDA y QDA. Por cada fila se encuentra el accuracy obtenido en test para la partición correspondiente. En esta sección utilizaremos el test de Wilcoxon para hacer comparaciones por pares y el de Friedman (con Post-Hoc Holm) para hacer una comparativa conjunta. Debido a que los valores de accuracy tienen valores muy parecidos en las columnas (de hecho, hay bastantes repetidos). Dichos empates van en detrimento de la capacidad de rechazar la hipótesis nula (esto es, que los algoritmos no tienen diferencias significativas entre sí). Dado que los tests no paramétricos se basan en rankings, los empates aporta información nula a dicha ordenación y el p-valor resultante tiende a ser peor. En la vida real, necesitaríamos buscar nuevas muestras que nos proporcionaran valores distintos para así dar lugar a variabilidad. Aquí, nos ceñiremos a los resultados obtenidos dado que las particiones están fijas.

\subsubsection{1NN vs LDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.005825024$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{1NN vs QDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.005729376$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{3NN vs LDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.005825024$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{3NN vs QDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.005857099$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{LDA vs QDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 0 y $R^{-}$ de 55, alcanzando un p-valor de $0.00588927$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{Comparativa general con el test de Friedman}

Utilizamos el test de Friedman para comparar globalmente los algoritmos. En él, establecemos como hipótesis nula que no hay diferencias significativas entre los algoritmos. Estos son los resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{friedman-c.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados del test de Friedman para clasificación} 
	\label{fig:friedman-c}
\end{figure}

Como podemos ver, el p-valor es bastante menor que 0.05, por lo que debemos rechazar la hipótesis nula. Por tanto, consideramos que hay diferencias significativas al menos entre un par de algoritmos. Vemos la diferencias a través del Post-Hoc

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{ph-c.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Post Hoc Holm en clasificación} 
	\label{fig:ph-c}
\end{figure}

Existen diferencias significativas entre QDA y 1NN (a favor de 1NN), QDA y 3NN (a favor de 3NN), QDA y LDA (a favor de QDA) con un $96.6\%$ de confianza, al igual que LDA y 1NN (a favor de 1NN) y LDA y 3NN (a favor de 3NN). 1NN y 3NN pueden considerarse equivalentes.

\subsection{Comparación de algoritmos en entrenamiento}

Por último, esta sección se encarga de comparar la actuación de los algoritmos en training, para poder diagnosticar posibles sobreaprendizaje. En primer lugar, muestro la tabla de resultados para training.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{tabla-res-c-tr.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Tabla de resultados para training} 
	\label{fig:res-c-tr}
\end{figure}

\subsubsection{1NN vs LDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.001953125$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{1NN vs QDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.005857099$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{3NN vs LDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.001953125$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{3NN vs QDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 55 y $R^{-}$ de 0, alcanzando un p-valor de $0.005857099$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.

\subsubsection{LDA vs QDA}

Realizamos el test de Wilcoxon para tratar de encontrar diferencias significativas en los algoritmos. Tras realizarlo, encontramos un $R^{+}$ de 0 y $R^{-}$ de 55, alcanzando un p-valor de $0.00588927$, por lo que tenemos que rechazar la hipótesis de que los algoritmos no tengan diferencias significativas.


\subsubsection{Comparativa general con Friedman}

Utilizamos el test de Friedman para comparar globalmente los algoritmos. En él, establecemos como hipótesis nula que no hay diferencias significativas entre los algoritmos. Estos son los resultados:

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{friedman-tr-c.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Resultados del test de Friedman en training} 
	\label{fig:f-c-tr}
\end{figure}

Como podemos ver, el p-valor es bastante menor que 0.05, por lo que debemos rechazar la hipótesis nula. Por tanto, consideramos que hay diferencias significativas al menos entre un par de algoritmos. Vemos la diferencias a través del Post-Hoc

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{ph-tr-c.png}  %el parámetro scale permite agrandar o chicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Post Hoc Holm en training clasificación} 
	\label{fig:ph-tr-c}
\end{figure}

Existen diferencias significativas entre QDA y 1NN (a favor de 1NN), QDA y 3NN (a favor de 3NN), QDA y LDA (a favor de QDA) con un $96.6\%$ de confianza, al igual que LDA y 1NN (a favor de 1NN) y LDA y 3NN (a favor de 3NN). 1NN y 3NN pueden considerarse equivalentes. Como podemos ver, descartamos sobreaprendizaje porque los resultados coinciden.


\newpage
\section{Bibliografía}

%------------------------------------------------

\bibliography{citas} %archivo citas.bib que contiene las entradas 
\bibliographystyle{plain} % hay varias formas de citar

\addcontentsline{toc}{section}{Apéndice 1: Código Vowel}
\addcontentsline{toc}{section}{Apéndice 2: Código Wankara}
\end{document}
